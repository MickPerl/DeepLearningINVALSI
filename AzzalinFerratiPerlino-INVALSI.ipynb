{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Modello di deep learning per predizione dropout scolastico su dati INVALSI\r\n",
    "Progetto del corso di **Intelligenza Artificiale**, A.A. 2020/2021\r\n",
    "\r\n",
    "**LM Informatica**, **Alma Mater Studiorum - Università di Bologna**\r\n",
    "\r\n",
    "Realizzato da:\r\n",
    "- Marco Ferrati, matr. 983546\r\n",
    "- Michele Perlino, matr. 983733\r\n",
    "- Tommaso Azzalin, matr. 985911"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Per aprire il notebook corrente sulla piattaforma Google Colab cliccare su [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MickPerl/MachineLearningProject/blob/main/AzzalinFerratiPerlino-INVALSI.ipynb)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup dell'ambiente"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installazione delle librerie necessarie"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip3 install --no-cache-dir -r requirements.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import delle librerie fondamentali per l'analisi dei dati"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\n",
    "from beautifultable import BeautifulTable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import IntegerLookup\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import src.config as cfg\n",
    "from src.mapping_domande_ambiti_processi import MAPPING_DOMANDE_AMBITI_PROCESSI\n",
    "from src.column_converters import COLUMN_CONVERTERS"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import del dataset originale"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Eseguire per: analisi dataset\n",
    "\"\"\"\n",
    "original_dataset = pd.read_csv(cfg.ORIGINAL_DATASET, sep=';', converters=COLUMN_CONVERTERS)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/public/tommaso.azzalin/.vscode-server/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:327199)",
      "at w.execute (/public/tommaso.azzalin/.vscode-server/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:326520)",
      "at w.start (/public/tommaso.azzalin/.vscode-server/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:322336)",
      "at async t.CellExecutionQueue.executeQueuedCells (/public/tommaso.azzalin/.vscode-server/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:336863)",
      "at async t.CellExecutionQueue.start (/public/tommaso.azzalin/.vscode-server/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:336403)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDA del dataset originale\r\n",
    "Il codice che segue realizza il processo EDA, acronimo che sta per *exploratory data analysis*, al fine di scandagliare i punti di attenzione del dataset a disposizione."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "original_dataset.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Come restituito dalla funzione `info()`, il dataset presenta $342226$ righe e $104$ colonne."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "original_dataset.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il dataset contiene svariate informazioni relative a studenti che hanno ultimato il ciclo di studi delle superiori: l'obiettivo del progetto è la progettazione e implementazione di un classificatore capace di predire, sulla base dei risultati conseguiti al test INVALSI di terza media, quali studenti registreranno un *dropout*.\\\n",
    "Il concetto di *dropout* può essere declinato su due livelli:\n",
    "- **implicito**: si dice che lo studente ha registrato un dropout implicito nel caso in cui non abbia acquisito le minime conoscenze e competenze, per cui presenta lacune formative;\n",
    "- **esplicito**: si dice che lo studente ha registrato un dropout esplicito nel caso in cui non abbia conseguito il diploma."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ricerca di colonne con alte percentuali di valori nulli"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Columns with high null values percentages:\")\n",
    "\n",
    "table = BeautifulTable()\n",
    "table.columns.header = [\"\", \"Type\",\"Ratio null values\"]\n",
    "\n",
    "for col in original_dataset.columns :\n",
    "    ratio_null_values = original_dataset[col].isnull().mean().round(3)\n",
    "    if ratio_null_values > 0:\n",
    "        table.rows.append([col, str(original_dataset[col].dtypes), ratio_null_values]) \n",
    "        \n",
    "table.columns.alignment = BeautifulTable.ALIGN_LEFT\n",
    "table.set_style(BeautifulTable.STYLE_SEPARATED)\n",
    "table.rows.sort('Ratio null values')\n",
    "print(table)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "columns_high_ratio_null_values = [\"codice_orario\", \"PesoClasse\", \"PesoScuola\", \"PesoTotale_Matematica\"]\n",
    "columns_lower_ratio_null_values = [\n",
    "    \"voto_scritto_ita\",  # 0.683\n",
    "    \"voto_scritto_mat\",  # 0.113\n",
    "    \"voto_orale_ita\",  # 0.683\n",
    "    \"voto_orale_mat\"  # 0.114\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ricerca colonne con un numero basso di valori distinti "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Columns with unique values:\")\n",
    "\n",
    "table = BeautifulTable()\n",
    "table.columns.header = [\"\", \"Ratio distinct values\"]\n",
    "\n",
    "for col in original_dataset.columns:\n",
    "    ratio_unique_vals = round(original_dataset[col].nunique() / len(original_dataset), 3)\n",
    "    if ratio_unique_vals  > 0.1 :\n",
    "        table.rows.append([col, ratio_unique_vals]) \n",
    "\n",
    "table.columns.alignment = BeautifulTable.ALIGN_LEFT\n",
    "table.set_style(BeautifulTable.STYLE_SEPARATED)\n",
    "table.rows.sort('Ratio distinct values')\n",
    "print(table)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Come era prevedibile, `Unnamed: 0` e `CODICE_STUDENTE` presentano una proporzione di valori distinti sul totale delle righe pari a 1, in quanto trattasi di indici/codici che identificano univocamente gli studenti. Queste due colonne potranno essere eliminate, dato che non portano alcuna informazione che possa aiutare a ravvisare relazioni tra gli studenti."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "columns_with_unique_values = [\"Unnamed: 0\", \"CODICE_STUDENTE\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ricerca colonne con un singolo valore"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Columns with just one value:\")\n",
    "for col in original_dataset.columns:\n",
    "    unique_vals = original_dataset[col].nunique()\n",
    "    if unique_vals == 1:\n",
    "        print(col)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Similmente, queste colonne possono essere eliminate in quanto non distinguono in alcuna maniera gli studenti."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "columns_with_just_one_value = [\"macrotipologia\", \"livello\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rimozione delle colonne superflue"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Eseguire per: analisi dataset\n",
    "\"\"\"\n",
    "cleaned_original_dataset: pd.DataFrame = original_dataset.drop(\n",
    "    columns_high_ratio_null_values + \n",
    "    columns_with_unique_values + \n",
    "    columns_with_just_one_value, \n",
    "    axis=1\n",
    ")\n",
    "cleaned_original_dataset.to_csv(cfg.CLEANED_DATASET)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Eseguire per: analisi dataset\n",
    "Attenzione: inutile eseguire se si è eseguita la precedente cella.\n",
    "\"\"\"\n",
    "cleaned_original_dataset = pd.read_csv(cfg.CLEANED_DATASET)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if \"Unnamed: 0\" in cleaned_original_dataset.columns:\n",
    "    cleaned_original_dataset.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generalizzazione dataset per supportare altre coorti di studenti\n",
    "Addestrando la rete con le domande specifiche di un certo test INVALSI non si ottiene un classificatore riutilizzabile per coorti successive. Pertanto, abbiamo pensato di mappare le feature inerenti alle domande in uno spazio più generico che permetta di cogliere la semantica delle domande piuttosto che la loro rappresentazione letterale; mediante le griglie di correzione fornite ai docenti, abbiamo notato che ogni domanda è caratterizzato da uno o più ambiti e processi: questa corrispondenza ha ispirato la trasformazione dello spazio di rappresentazione delle domande che riportiamo di seguito. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nel file `mapping_domande_ambiti_processi` posizionato nella cartella `src` abbiamo creato un dizionario le cui chiavi sono le domande e i valori gli ambiti e i processi corrispondenti. Dopo averlo importato nel notebook corrente, abbiamo estratto i distinti ambiti e processi per poi calcolarne il numero di domande che caratterizzano."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list_ambiti_processi = [AP for val in MAPPING_DOMANDE_AMBITI_PROCESSI.values() for AP in val]\n",
    "ambiti_processi = set(list_ambiti_processi)\n",
    "conteggio_ambiti_processi = {AP: list_ambiti_processi.count(AP) for AP in ambiti_processi}   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abbiamo proceduto con l'aggiungere al dataset originale colonne recanti il nome degli ambiti e processi, inizializzate a 0 per tutte le righe."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Eseguire per: analisi dataset\n",
    "\"\"\"\n",
    "dataset_with_ambiti_processi = cleaned_original_dataset.copy()\n",
    "for AP in ambiti_processi:\n",
    "    dataset_with_ambiti_processi[AP] = 0.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Col codice seguente, ogni studente sarà caratterizzato da un valore per ogni ambito e processo corrispondente alla proporzione di domande che vi si riferivano e a cui ha risposto correttamente: ad esempio, nel caso un processo `x` vada a caratterizzare 10 domande e lo studente risponda correttamente a 5 di queste ultime, allora il valore che quello studente presenterà sotto il processo `x` sarà pari a $0.5$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Eseguire per: rimozione feature sulle domande e aggiunta feature sugli ambiti e processi\n",
    "\"\"\"\n",
    "questions_columns = [col for col in list(cleaned_original_dataset) if re.search(\"^D\\d\", col)]\n",
    "\n",
    "for i, row in dataset_with_ambiti_processi.iterrows():\n",
    "    for question, APs in MAPPING_DOMANDE_AMBITI_PROCESSI.items():\n",
    "        if row[question] == True:   # se ha risposto correttamente\n",
    "            for AP in APs:\n",
    "                dataset_with_ambiti_processi.at[i, AP] += 1 / conteggio_ambiti_processi[AP]\n",
    "\n",
    "dataset_ap = dataset_with_ambiti_processi.drop(questions_columns, axis=1)\n",
    "\n",
    "dataset_ap.to_csv(cfg.CLEANED_DATASET_WITH_AP)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Eseguire per: rimozione feature sulle domande e aggiunta feature sugli ambiti e processi\n",
    "Attenzione: inutile eseguire se si è eseguita la precedente cella.\n",
    "\"\"\"\n",
    "dataset_ap = pd.read_csv(cfg.CLEANED_DATASET_WITH_AP)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if \"Unnamed: 0\" in dataset_ap.columns:\n",
    "    dataset_ap.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analisi della correlazione fra feature"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr_matrix = dataset_ap.corr(method='pearson').round(2)\n",
    "corr_matrix.style.background_gradient(cmap='YlOrRd')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Emerge un'alta correlazione ($0.87$) tra i voti della stessa materia, come era prevedibile, mentre una correlazione abbastanza alta tra materie differenti ($0.75$). La correlazione pari a $1$ tra `pu_ma_gr` e `pu_ma_no` si spiega considerando che la seconda è la normalizzazione della prima, per cui portano esattamente la stessa informazione.\r\n",
    "\r\n",
    "Abbiamo ritenuto interessante indagare la correlazione sussistente tra i voti agli scritti e agli orali, i punteggi finali ottenuti al test e gli ambiti e i processi: abbiamo previsto solo valori positivi di correlazione, in quanto a voti maggiori, corrispondono punteggi finali maggiori, come anche per i processi e ambiti. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "interesting_to_check_if_correlated_columns = [\n",
    "    # Alta correlazione fra voti della stessa materia, abbastanza correlate fra materie diverse\n",
    "    \"voto_scritto_ita\",\n",
    "    \"voto_orale_ita\",\n",
    "    \"voto_scritto_mat\",\n",
    "    \"voto_orale_mat\",\n",
    "    # Correlazione totale, abbastanza correlate con voti\n",
    "    \"pu_ma_no\"\n",
    "] + list(ambiti_processi)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "check_corr_dataset = dataset_ap[interesting_to_check_if_correlated_columns].corr(method='pearson').round(2)\n",
    "check_corr_dataset.style.background_gradient(cmap='YlOrRd')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "La nostra previsione è stata confermata."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rimozione colonne altamente correlate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO Rimozione colonne altamente correlate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analisi dei tipi delle colonne"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Lista colonne e tipi:\")\r\n",
    "\r\n",
    "table = BeautifulTable()\r\n",
    "table.columns.header = [\"\", \"Type\"]\r\n",
    "\r\n",
    "for col in dataset_ap.columns :\r\n",
    "    table.rows.append([col, dataset_ap[col].dtypes])\r\n",
    "        \r\n",
    "table.columns.alignment = BeautifulTable.ALIGN_LEFT\r\n",
    "table.set_style(BeautifulTable.STYLE_SEPARATED)\r\n",
    "print(table)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "continuous_features = columns_lower_ratio_null_values + \\\r\n",
    "                      [\"pu_ma_gr\", \"pu_ma_no\", \"Fattore_correzione_new\", \"Cheating\", \"WLE_MAT\", \"WLE_MAT_200\", \"WLE_MAT_200_CORR\",\r\n",
    "                       \"pu_ma_no_corr\"] + \\\r\n",
    "                      list(ambiti_processi) # Feature sui voti, feature elencate, ambiti e processi\r\n",
    "ordinal_features = [\r\n",
    "    \"n_stud_prev\", \"n_classi_prev\", \"LIVELLI\", \"voto_scritto_mat\", \"voto_orale_mat\"\r\n",
    "] + ([\"voto_scritto_ita\", \"voto_orale_ita\"] if cfg.FILL_NAN != \"remove\" else []) # se si rimuovono le colonne dei voti di italiano non vanno messe tra le feature\r\n",
    "int_categorical_features = [\r\n",
    "    \"CODICE_SCUOLA\", \"CODICE_PLESSO\", \"CODICE_CLASSE\", \"campione\", \"prog\",\r\n",
    "]\r\n",
    "str_categorical_features = [\r\n",
    "    \"sesso\", \"mese\", \"anno\", \"luogo\", \"eta\", \"freq_asilo_nido\", \"freq_scuola_materna\",\r\n",
    "    \"luogo_padre\", \"titolo_padre\", \"prof_padre\", \"luogo_madre\", \"titolo_madre\", \"prof_madre\",\r\n",
    "    \"regolarità\", \"cittadinanza\", \"cod_provincia_ISTAT\", \"Nome_reg\",\r\n",
    "    \"Cod_reg\", \"Areageo_3\", \"Areageo_4\", \"Areageo_5\", \"Areageo_5_Istat\"\r\n",
    "]\r\n",
    "bool_features = [\"Pon\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gestione dei valori nulli\r\n",
    "Il dataset in considerazione presenta molti valori nulli.\\\r\n",
    "Vi sono diverse tecniche per gestirli, tra cui:\r\n",
    "- sostituzione del valore nullo con un indice di sintesi (media, mediana, moda) della colonna in considerazione: la scelta dell'indice dipende da vari fattori, tra cui la forma della distribuzione del certo attributo;\r\n",
    "- rimozione della riga corrispondente: viene adottata solitamente quando la colonna presenta pochi valori nulli e/o la riga presenta molti valori nulli;\r\n",
    "- rimozione della colonna corrispondente: viene adottata solitamente quando la colonna presenta un alto numero di valori nulli."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_ap[\"sigla_provincia_istat\"].fillna(value=\"ND\", inplace=True)\r\n",
    "# TODO Trovare un modo migliore per effettuare il rimpiazzo dei non disponibili.\r\n",
    "dataset_ap[\"sigla_provincia_istat\"].fillna(value=\"ND\", inplace=True)\r\n",
    "if cfg.FILL_NAN == \"median\":\r\n",
    "    dataset_ap[\"voto_scritto_ita\"].fillna(value=dataset_ap[\"voto_scritto_ita\"].median(), inplace=True)\r\n",
    "    dataset_ap[\"voto_orale_ita\"].fillna(value=dataset_ap[\"voto_orale_ita\"].median(), inplace=True)\r\n",
    "    dataset_ap[\"voto_scritto_mat\"].fillna(value=dataset_ap[\"voto_scritto_mat\"].median(), inplace=True)\r\n",
    "    dataset_ap[\"voto_orale_mat\"].fillna(value=dataset_ap[\"voto_orale_mat\"].median(), inplace=True)\r\n",
    "elif cfg.FILL_NAN == \"mean\":\r\n",
    "    dataset_ap[\"voto_scritto_ita\"].fillna(value=dataset_ap[\"voto_scritto_ita\"].mean(), inplace=True)\r\n",
    "    dataset_ap[\"voto_orale_ita\"].fillna(value=dataset_ap[\"voto_orale_ita\"].mean(), inplace=True)\r\n",
    "    dataset_ap[\"voto_scritto_mat\"].fillna(value=dataset_ap[\"voto_scritto_mat\"].mean(), inplace=True)\r\n",
    "    dataset_ap[\"voto_orale_mat\"].fillna(value=dataset_ap[\"voto_orale_mat\"].mean(), inplace=True)\r\n",
    "elif cfg.FILL_NAN == \"mode\":\r\n",
    "    dataset_ap[\"voto_scritto_ita\"].fillna(value=dataset_ap[\"voto_scritto_ita\"].mode(), inplace=True)\r\n",
    "    dataset_ap[\"voto_orale_ita\"].fillna(value=dataset_ap[\"voto_orale_ita\"].mode(), inplace=True)\r\n",
    "    dataset_ap[\"voto_scritto_mat\"].fillna(value=dataset_ap[\"voto_scritto_mat\"].mode(), inplace=True)\r\n",
    "    dataset_ap[\"voto_orale_mat\"].fillna(value=dataset_ap[\"voto_orale_mat\"].mode(), inplace=True)\r\n",
    "elif cfg.FILL_NAN == \"remove\":\r\n",
    "    # Rimuovere colonne voti ita\r\n",
    "    # Rimuovere record con dati nulli in voti mat\r\n",
    "    dataset_ap.drop([\"voto_scritto_ita\", \"voto_orale_ita\"], axis=1, inplace=True)\r\n",
    "    dataset_ap.dropna([\"voto_scritto_mat\", \"voto_orale_mat\"], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning\r\n",
    "## Suddivisione dataset in training e test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_training_set, df_test_set = train_test_split(dataset_ap, test_size=cfg.TEST_SET_PERCENT)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analisi e gestione dello sbilanciamento del dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nr_nodrop, nr_drop = np.bincount(dataset_ap['DROPOUT'])\r\n",
    "total_records = nr_drop + nr_nodrop\r\n",
    "nl = '\\n'\r\n",
    "print(\r\n",
    "    f\"Total number of records: {total_records}{nl}\\\r\n",
    "        {nl}\\\r\n",
    "Total num. DROPOUT: {nr_drop}{nl}\\\r\n",
    "Total num. NO DROPOUT: {nr_nodrop}{nl}\\\r\n",
    "    {nl}\\\r\n",
    "Ratio DROPOUT/TOTAL: {round(nr_drop / total_records, 2)}{nl}\\\r\n",
    "Ratio NO DROPOUT/TOTAL: {round(nr_nodrop / total_records, 2)}{nl}\\\r\n",
    "    {nl}\\\r\n",
    "Ratio DROPOUT/NO DROPOUT: {round(nr_drop / nr_nodrop, 2)}\"\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Campionamento: Random undersampling o SMOTE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Eseguire per: campionamento\r\n",
    "\"\"\"\r\n",
    "if cfg.SAMPLING_TO_PERFORM == \"random_undersampling\":\r\n",
    "    # class_nodrop contiene i record della classe sovrarappresentata, ovvero SENZA DROPOUT.\r\n",
    "    class_nodrop = df_training_set[df_training_set['DROPOUT'] == False]\r\n",
    "    # class_drop contiene i record della classe sottorappresentata, ovvero CON DROPOUT.\r\n",
    "    class_drop = df_training_set[df_training_set['DROPOUT'] == True]\r\n",
    "\r\n",
    "    # Sotto campionamento di class_drop in modo che abbia stessa cardinalità di class_nodrop\r\n",
    "    class_nodrop = class_nodrop.sample(len(class_drop))\r\n",
    "\r\n",
    "    print(f'Class NO DROPOUT: {len(class_nodrop):,}')\r\n",
    "    print(f'Classe DROPOUT: {len(class_drop):,}')\r\n",
    "\r\n",
    "    df_training_set = class_drop.append(class_nodrop)\r\n",
    "    df_training_set = df_training_set.sample(frac=1)\r\n",
    "elif cfg.SAMPLING_TO_PERFORM == \"SMOTE\":\r\n",
    "    print(\"SMOTE not yet implemented\")\r\n",
    "else:\r\n",
    "    print(f\"SAMPLING_TO_PERFORM = {cfg.SAMPLING_TO_PERFORM} not recognized.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if \"Unnamed: 0\" in df_training_set.columns:\r\n",
    "    df_training_set.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing per creazione del modello di Deep Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Suddivisione del dataset in training e test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_training_set, df_validation_set = train_test_split(df_training_set, test_size=cfg.VALIDATION_SET_PERCENT)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conversione dei dati da DataFrame (Pandas) a Dataset (Tensorflow/Keras)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def pd_dataframe_to_tf_dataset(dataframe: pd.DataFrame):\r\n",
    "    copied_df = dataframe.copy()\r\n",
    "    dropout_col = copied_df.pop(\"DROPOUT\")\r\n",
    "    \"\"\"\r\n",
    "    Dato che il dataframe ha dati eterogenei lo convertiamo a dizionario,\r\n",
    "    in cui le chiavi sono i nomi delle colonne e i valori sono i valori della colonna.\r\n",
    "    Infine bisogna indicare la colonna target.\r\n",
    "    \"\"\"\r\n",
    "    tf_dataset = tf.data.Dataset.from_tensor_slices((dict(copied_df), dropout_col))\r\n",
    "    tf_dataset = tf_dataset.shuffle(buffer_size=len(copied_df))\r\n",
    "    return tf_dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds_training_set = pd_dataframe_to_tf_dataset(df_training_set)\r\n",
    "ds_validation_set = pd_dataframe_to_tf_dataset(df_validation_set)\r\n",
    "ds_test_set = pd_dataframe_to_tf_dataset(df_test_set)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Suddivisione del dataset in batch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds_training_set = ds_training_set.batch(cfg.BATCH_SIZE, drop_remainder=True)\r\n",
    "ds_validation_set = ds_validation_set.batch(cfg.BATCH_SIZE, drop_remainder=True)\r\n",
    "ds_test_set = ds_test_set.batch(cfg.BATCH_SIZE, drop_remainder=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creazione dei layer di input per ogni feature"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input_layers = {}\r\n",
    "for name, column in df_training_set.items():\r\n",
    "    if name == \"DROPOUT\":\r\n",
    "        continue\r\n",
    "\r\n",
    "    if name in continuous_features:\r\n",
    "        dtype = tf.float32\r\n",
    "    elif name in ordinal_features or name in int_categorical_features or name in bool_features:\r\n",
    "        dtype = tf.int64\r\n",
    "    else:  # str_categorical_features\r\n",
    "        dtype = tf.string\r\n",
    "\r\n",
    "    input_layers[name] = tf.keras.Input(shape=(), name=name, dtype=dtype)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoding delle feature in base al loro tipo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preprocessed_features = []\r\n",
    "\r\n",
    "def stack_dict(inputs, fun=tf.stack):\r\n",
    "    values = []\r\n",
    "    for key in sorted(inputs.keys()):\r\n",
    "        values.append(tf.cast(inputs[key], tf.float32))\r\n",
    "\r\n",
    "    return fun(values, axis=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Preprocessing colonne con dati booleani\r\n",
    "for name in bool_features:\r\n",
    "    inp = input_layers[name]\r\n",
    "    inp = inp[:, tf.newaxis]\r\n",
    "    float_value = tf.cast(inp, tf.float32)\r\n",
    "    preprocessed_features.append(float_value)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Preprocessing colonne con dati interi ordinali\n",
    "ordinal_inputs = {}\n",
    "for name in ordinal_features:\n",
    "    ordinal_inputs[name] = input_layers[name]\n",
    "\n",
    "normalizer = Normalization(axis=-1)\n",
    "normalizer.adapt(stack_dict(dict(df_training_set[ordinal_features])))\n",
    "ordinal_inputs = stack_dict(ordinal_inputs)\n",
    "ordinal_normalized = normalizer(ordinal_inputs)\n",
    "preprocessed_features.append(ordinal_normalized)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Preprocessing colonne con dati continui\r\n",
    "continuous_inputs = {}\r\n",
    "for name in continuous_features:\r\n",
    "    continuous_inputs[name] = input_layers[name]\r\n",
    "\r\n",
    "normalizer = Normalization(axis=-1)\r\n",
    "normalizer.adapt(stack_dict(dict(df_training_set[continuous_features])))\r\n",
    "continuous_inputs = stack_dict(continuous_inputs)\r\n",
    "continuous_normalized = normalizer(continuous_inputs)\r\n",
    "preprocessed_features.append(continuous_normalized)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Preprocessing colonne con dati categorici stringa\r\n",
    "for name in str_categorical_features:\r\n",
    "    vocab = sorted(set(df_training_set[name]))\r\n",
    "\r\n",
    "    lookup = StringLookup(vocabulary=vocab, output_mode='one_hot')\r\n",
    "\r\n",
    "    x = input_layers[name][:, tf.newaxis]\r\n",
    "    x = lookup(x)\r\n",
    "\r\n",
    "    preprocessed_features.append(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Preprocessing colonne con dati categorici interi\r\n",
    "for name in int_categorical_features:\r\n",
    "    vocab = sorted(set(df_training_set[name]))\r\n",
    "\r\n",
    "    lookup = IntegerLookup(vocabulary=vocab, output_mode='one_hot')\r\n",
    "\r\n",
    "    x = input_layers[name][:, tf.newaxis]\r\n",
    "    x = lookup(x)\r\n",
    "\r\n",
    "    preprocessed_features.append(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assemblaggio dei vari layer e creazione del modello"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# initializer = tf.keras.initializers.glorot_uniform(seed=19)\r\n",
    "\r\n",
    "preprocessed = tf.concat(preprocessed_features, axis=-1)\r\n",
    "\r\n",
    "preprocessor = tf.keras.Model(input_layers, preprocessed)\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "body = tf.keras.Sequential(\r\n",
    "    [tf.keras.layers.Dense(cfg.NEURONS, activation=cfg.DENSE_LAYER_ACTIVATION) for _ in range(cfg.NUMBER_OF_LAYERS)] +\r\n",
    "    [tf.keras.layers.Dropout(cfg.DROPOUT_LAYER_RATE)] if cfg.DROPOUT_LAYER else [] +\r\n",
    "    [tf.keras.layers.Dense(1, activation=cfg.OUTPUT_ACTIVATION_FUNCTION)]\r\n",
    ")\r\n",
    "\"\"\"\r\n",
    "body = tf.keras.Sequential()\r\n",
    "for _ in range(cfg.NUMBER_OF_LAYERS):\r\n",
    "    if cfg.LEAKY_RELU:\r\n",
    "        body.add(tf.keras.layers.Dense(cfg.NEURONS))\r\n",
    "        body.add(tf.keras.layers.LeakyReLU())\r\n",
    "    else:\r\n",
    "        body.add(tf.keras.layers.Dense(cfg.NEURONS, activation=cfg.DENSE_LAYER_ACTIVATION))\r\n",
    "if cfg.DROPOUT_LAYER:\r\n",
    "    body.add(tf.keras.layers.Dropout(cfg.DROPOUT_LAYER_RATE))\r\n",
    "body.add(tf.keras.layers.Dense(1, activation=cfg.OUTPUT_ACTIVATION_FUNCTION))\r\n",
    "\r\n",
    "x = preprocessor(input_layers)\r\n",
    "\r\n",
    "result = body(x)\r\n",
    "\r\n",
    "model = tf.keras.Model(input_layers, result)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualizzazione tabellare del modello\n",
    "from keras.utils.vis_utils import plot_model\n",
    "model.summary()\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compilazione del modello e scelta delle metriche"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=cfg.LEARNING_RATE),\r\n",
    "              loss=tf.losses.BinaryCrossentropy(),\r\n",
    "              metrics=[\r\n",
    "                  tf.metrics.Accuracy(),\r\n",
    "                  tf.metrics.BinaryAccuracy(),\r\n",
    "                  tf.metrics.Precision(),\r\n",
    "                  tf.metrics.Recall(),\r\n",
    "                  tf.metrics.FalseNegatives(),\r\n",
    "                  tf.metrics.FalsePositives(),\r\n",
    "                  tf.metrics.TrueNegatives(),\r\n",
    "                  tf.metrics.TruePositives()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Early stopping"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\r\n",
    "Definizione dello stopper per evitare che la reti continui ad addestrarsi quando non ci sono miglioramenti della loss \r\n",
    "(val_loss = funzione di costo sul validation set) per piu' di 3 epoche\r\n",
    "\"\"\"\r\n",
    "early_stopper = EarlyStopping(monitor=\"val_loss\", patience=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.fit(ds_training_set,\r\n",
    "          epochs=cfg.EPOCH,\r\n",
    "          batch_size=cfg.BATCH_SIZE,\r\n",
    "          validation_data=ds_validation_set,\r\n",
    "          callbacks=[early_stopper],\r\n",
    "          verbose=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "score = model.evaluate(ds_test_set)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Risultati ottenuti"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "| Epoche | Neuroni | Batch | Tecnica di sampling | Layer lineari | Tasso apprendimento | Dropout | Tasso di dropout | Accuratezza in training | Accuratezza in test | Note aggiuntive |\r\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |\r\n",
    "|     10 |     128 |    32 |       Undersampling |            10 |               0.001 |      No |                - |                  0.2339 |              0.2336 | C'erano colonne con alta correlazione. |\r\n",
    "|     50 |     128 |    32 |       Undersampling |            10 |               0.001 |      No |                - |                  0.6938 |              0.6874 | C'erano colonne con alta correlazione. |\r\n",
    "|     50 |     256 |    32 |       Undersampling |            10 |               0.001 |      No |                - |                  0.6944 |              0.6873 | C'erano colonne con alta correlazione. |\r\n",
    "|     50 |     128 |   128 |       Undersampling |            10 |               0.001 |      No |                - |                  0.2386 |              0.2341 | C'erano colonne con alta correlazione. Perché è così pessimo il risultato? |"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Per info su come formattare Markdown: [clicca qui](https://medium.com/analytics-vidhya/the-ultimate-markdown-guide-for-jupyter-notebook-d5e5abf728fd)."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('venv': virtualenv)"
  },
  "interpreter": {
   "hash": "d5eff28add82fd6e8c4693fed40b1715c623a35f94f64d25fc933aca83306cd5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}