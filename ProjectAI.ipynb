{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "colab": {
   "name": "ProjectAI.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "accelerator": "TPU",
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1QPsU3xbgoY25jiMgoWamYhxKLT_iMHYA#scrollTo=XDspGgUS55Xo)"
   ],
   "metadata": {
    "id": "XDspGgUS55Xo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Installazione delle librerie necessarie per l'analisi dei dati"
   ],
   "metadata": {
    "id": "HkcKgoFzNz6q"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "%pip install scikit-learn==0.24.2 cluster-over-sampling tensorflow python-dotenv"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: scikit-learn==0.24.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (0.24.2)\n",
      "Requirement already satisfied: cluster-over-sampling in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (0.2.6)\n",
      "Requirement already satisfied: tensorflow in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (2.1.0)\n",
      "Requirement already satisfied: python-dotenv in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (0.18.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn==0.24.2) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn==0.24.2) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn==0.24.2) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn==0.24.2) (2.1.0)\n",
      "Requirement already satisfied: imbalanced-learn>=0.6.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from cluster-over-sampling) (0.8.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (2.1.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (1.38.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: h5py in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.32.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (50.3.0)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from h5py->keras-applications>=1.0.8->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4edKDd_3aPHe",
    "outputId": "e4667bc0-ff8e-4939-b35f-24e7ef18f65c"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import delle librerire fondamentali per l'analisi dei dati"
   ],
   "metadata": {
    "id": "NUg8I6hAdzjz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "import re\r\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {
    "id": "dxT1q959d-rL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ottenimento dataset\n",
    "La variabile `DATASET_PATH` sar√† settata con il valore corretto.\n",
    "\n",
    "**Settare a** `True` **la variabile** `from_gdrive` **per accedere al dataset tramite Google Drive. Settarla a** `False`\n",
    "**per accedere al dataset in locale.**"
   ],
   "metadata": {
    "id": "kcnbPK6Ibq7D"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from_gdrive = False\r\n",
    "if from_gdrive:\r\n",
    "    from google.colab import drive\r\n",
    "    drive.mount(\"/content/gdrive\")\r\n",
    "    %cd gdrive/MyDrive/ProjectAI/\r\n",
    "    DATASET_PATH = \"Data/invalsi_mat_2014.csv\"\r\n",
    "else:\r\n",
    "    DATASET_PATH = \"../invalsi_mat_2014.csv\""
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICIk29N7Rf88",
    "outputId": "77992ee0-3607-40ca-b79b-3c1a35859860"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "in_jupyter_notebook = True\r\n",
    "if in_jupyter_notebook:\r\n",
    "    from IPython.core.display import display, HTML\r\n",
    "    display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {
    "id": "FGOx3t8pZpnm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "from_azure = True\r\n",
    "if from_azure:\r\n",
    "    from azureml.core import Workspace\r\n",
    "    from os import environ\r\n",
    "    #%load_ext dotenv\r\n",
    "    #%dotenv\r\n",
    "    # Eseguire export $(cat .env | xargs)\r\n",
    "    subscription_id = environ.get('subscription_id')\r\n",
    "    resource_group = environ.get('resource_group')\r\n",
    "    workspace_name = environ.get('workspace_name')\r\n",
    "    workspace = Workspace(subscription_id, resource_group, workspace_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utility per tipi e conversioni"
   ],
   "metadata": {
    "id": "ImDtO788e8ZM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "from typing import List, Dict, Tuple\r\n",
    "string_list = List[str]\r\n",
    "one_hot_list = Tuple[int]\r\n",
    "one_hot_encoding_list = Dict[str, one_hot_list]\r\n",
    "one_hot_encoding_int = Dict[str, int]"
   ],
   "outputs": [],
   "metadata": {
    "id": "XRNMMf13oGTm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mappe e funzioni per conversioni valori del dataset in valori numerici o booleani"
   ],
   "metadata": {
    "id": "o38E8qc6eCgd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "def from_categorical_to_one_hot_int(categorical_data: string_list) -> one_hot_encoding_int:\r\n",
    "    dictionary_to_return = {}\r\n",
    "    for index, key in enumerate(categorical_data):\r\n",
    "        dictionary_to_return[key] = index\r\n",
    "    \r\n",
    "    return dictionary_to_return\r\n",
    "\r\n",
    "def from_categorical_to_one_hot_list(categorical_data: string_list) -> one_hot_encoding_list:\r\n",
    "    dictionary_to_return = {}\r\n",
    "    indexes = range(len(categorical_data))\r\n",
    "    for index, key in enumerate(categorical_data):\r\n",
    "        dictionary_to_return[key] = [1 if index == i else 0 for i in indexes]\r\n",
    "    \r\n",
    "    return dictionary_to_return\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_MESI = [\"Gennaio\", \"Febbraio\", \"Marzo\", \"Aprile\", \"Maggio\", \"Giugno\", \"Luglio\", \"Agosto\", \"Settembre\", \"Ottobre\", \"Novembre\", \"Dicembre\", \"Non disponibile\"]\r\n",
    "MESI = from_categorical_to_one_hot_int(list_MESI)\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_ANNI = [\"2000\", \"2001\", \"1999\", \"1998\", \"<=1997\", \">=2002\", \"Non disponibile\"]\r\n",
    "ANNI = from_categorical_to_one_hot_int(list_ANNI)\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_ETA = ['Mancante di sistema', 'Non disponibile', '6 anni', '5 anni', '10 anni o pi√π', '2 anni', '1 anno o prima', '9 anni', '8 anni', '4 anni', '7 anni', '3 anni']\r\n",
    "ETA = from_categorical_to_one_hot_int(list_ETA)\r\n",
    "\r\n",
    "def convert_question_result(result: str) -> bool:\r\n",
    "    return result == \"Corretta\" # alternativamente result == \"Errata\"\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_REGOLARITA = ['Regolare', 'Posticipatario', 'Anticipatario', 'Dato mancante']\r\n",
    "REGOLARITA = from_categorical_to_one_hot_int(list_REGOLARITA)\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_AREA_GEOGRAFICA_5_ISTAT = ['Sud', 'Nord est', 'Centro', 'Nord ovest', 'Isole']\r\n",
    "AREA_GEOGRAFICA_5_ISTAT = from_categorical_to_one_hot_int(list_AREA_GEOGRAFICA_5_ISTAT)\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_AREA_GEOGRAFICA_5 = ['Sud', 'Nord est', 'Centro', 'Nord ovest', 'Sud e isole']\r\n",
    "AREA_GEOGRAFICA_5 = from_categorical_to_one_hot_int(list_AREA_GEOGRAFICA_5)\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_AREA_GEOGRAFICA_4 = ['Mezzogiorno', 'Nord est', 'Centro', 'Nord ovest']\r\n",
    "AREA_GEOGRAFICA_4 = from_categorical_to_one_hot_int(list_AREA_GEOGRAFICA_4)\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_AREA_GEOGRAFICA_3 = ['Mezzogiorno', 'Nord', 'Centro']\r\n",
    "AREA_GEOGRAFICA_3 = from_categorical_to_one_hot_int(list_AREA_GEOGRAFICA_3)\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_REGIONI = ['Campania', 'Emilia-Romagna', 'Lazio', 'Piemonte', 'Puglia', 'Lombardia', 'Veneto', 'Sicilia', 'Prov. Aut. Trento', 'Friuli-Venezia Giulia', 'Abruzzo', 'Liguria', 'Toscana', 'Sardegna', 'Calabria', 'Molise', 'Marche', 'Umbria', 'Basilicata', 'Prov. Aut. Bolzano (l. it.)']\r\n",
    "REGIONI = from_categorical_to_one_hot_int(list_REGIONI)\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_PROVINCE = ['', 'RE', 'FR', 'TO', 'BA', 'CO', 'LE', 'RO', 'CT', 'RM', 'TA', 'BS', 'SA', 'TN', 'UD', 'FG', 'LT', 'AG', 'CH', 'PC', 'TS', 'SR', 'SP', 'PD', 'SI', 'PA', 'TP', 'BO', 'CA', 'CN', 'RC', 'TE', 'MI', 'LC', 'LU', 'FI', 'AQ', 'TV', 'RG', 'VA', 'GO', 'MO', 'GE', 'AL', 'CB', 'PR', 'OR', 'VE', 'MC', 'NO', 'PT', 'MN', 'VR', 'PI', 'AP', 'LO', 'VI', 'SV', 'PU', 'BG', 'AR', 'VT', 'LI', 'SS', 'BR', 'RA', 'TR', 'SO', 'IM', 'PZ', 'GR', 'AN', 'PN', 'ME', 'CR', 'FE', 'BI', 'PV', 'PG', 'VB', 'BL', 'PE', 'CS', 'CZ', 'AV', 'RN', 'CL', 'AT', 'MS', 'KR', 'RI', 'EN', 'CE', 'MT', 'VV', 'VC', 'NU', 'FC', 'PO', 'BZ', 'BN', 'IS', \r\n",
    "            'NA', # presente in cod_provincia_ISTAT ma non in sigla_provincia_istat\r\n",
    "            'PS', # presente in cod_provincia_ISTAT ma non in sigla_provincia_istat\r\n",
    "            'FO', # presente in cod_provincia_ISTAT ma non in sigla_provincia_istat\r\n",
    "            'LB', # presente in cod_provincia_ISTAT ma non in sigla_provincia_istat\r\n",
    "]\r\n",
    "PROVINCE = from_categorical_to_one_hot_int(list_PROVINCE)\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_CITTADINANZA = ['Italiano', 'Straniero II generazione', 'Straniero I generazione', 'Dato mancante']\r\n",
    "CITTADINANZA = from_categorical_to_one_hot_int(list_CITTADINANZA)\r\n",
    "\r\n",
    "list_VOTI_NUMERICI = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\r\n",
    "def voto_orale_decode(voto_orale: str) -> float:\r\n",
    "    if voto_orale in list_VOTI_NUMERICI:\r\n",
    "        return float(voto_orale)\r\n",
    "    elif voto_orale == 'Non disponibile':\r\n",
    "        return np.nan\r\n",
    "    elif voto_orale == 'Non classificato': \r\n",
    "        return 0.0\r\n",
    "\r\n",
    "list_VOTI_NAN = ['Non disponibile', 'Senza voto scritto']\r\n",
    "def voto_scritto_decode(voto_scritto: str) -> float:\r\n",
    "    if voto_scritto in list_VOTI_NUMERICI:\r\n",
    "        return float(voto_scritto)\r\n",
    "    elif voto_scritto in list_VOTI_NAN:\r\n",
    "        return np.nan\r\n",
    "    elif voto_scritto == 'Non classificato': \r\n",
    "        return 0.0\r\n",
    "\r\n",
    "def sesso_to_num(sesso: str) -> int:\r\n",
    "    return 0 if sesso == \"Maschio\" else 1\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_PROFESSIONI = ['1. Disoccupato/a', '2. Casalingo/a', '3. Dirigente, docente universitario, funzionario o ufficiale militare', '4. Imprenditore/proprietario agricolo', '5. Professionista dipendente, sottuff. militare o libero profession. (medico, av', '6. Lavoratore in proprio (commerciante, coltivatore diretto, artigiano, meccanic', '7. Insegnante, impiegato, militare graduato', '8. Operaio, addetto ai servizi/socio di cooperativa', '9. Pensionato/a', '10. Non disponibile']\r\n",
    "PROFESSIONI = from_categorical_to_one_hot_int(list_PROFESSIONI)\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_TITOLI = ['1. Licenza elementare', '2. Licenza media', '3. Qualifica professionale triennale', '4. Diploma di maturit√†', '5. Altro titolo di studio superiore al diploma (I.S.E.F., Accademia di Belle Art', '6. Laurea o titolo superiore (ad esempio Dottorato di Ricerca)', '7. Non disponibile']\r\n",
    "TITOLI = from_categorical_to_one_hot_int(list_TITOLI)\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_LUOGHI_GENITORI = ['Italia (o Repubblica di San Marino)', 'Unione Europea', 'Paese europeo Non UE', 'Altro', 'Non disponibile']\r\n",
    "LUOGHI_GENITORI = from_categorical_to_one_hot_int(list_LUOGHI_GENITORI)\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_FREQUENZA_SCUOLA = ['No', 'S√¨', 'Non disponibile']\r\n",
    "FREQUENZA_SCUOLA = from_categorical_to_one_hot_int(list_FREQUENZA_SCUOLA)\r\n",
    "\r\n",
    "#Features categorica -> One Hot Encoding\r\n",
    "list_LUOGO_DI_NASCITA = ['Italia (o Repubblica di San Marino)', 'Unione Europea', 'Paese europeo Non UE', 'Altro', 'Non disponibile']\r\n",
    "LUOGO_DI_NASCITA = from_categorical_to_one_hot_int(list_LUOGO_DI_NASCITA)"
   ],
   "outputs": [],
   "metadata": {
    "id": "Ix0xEhejePKl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definiamo le conversioni che si dovranno eseguire al momento dell'import."
   ],
   "metadata": {
    "id": "PB7HCRC7eemV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "columns_converters = {\r\n",
    "    \"CODICE_SCUOLA\": str, #identificativo della scuola (non considerato)\r\n",
    "    \"CODICE_PLESSO\": str, #identificativo del plesso (non considerato)\r\n",
    "    \"CODICE_CLASSE\": str, #identificato della classe (non considerato)\r\n",
    "    \"macrotipologia\": str, #categoria di scuola (non considerato)\r\n",
    "    \"campione\": int, #campione di riferimento (non considerato)\r\n",
    "    \"livello\": int, # (non considerato)\r\n",
    "    \"prog\": int,\r\n",
    "    \"CODICE_STUDENTE\": str, #codice dello studente (non considerato)\r\n",
    "    \"sesso\": sesso_to_num, #sesso dello studente\r\n",
    "    \"mese\": lambda month: MESI[month], #mese di nascita\r\n",
    "    \"anno\": lambda year: ANNI[year], #anno di nascita\r\n",
    "    \"luogo\": lambda luogo: LUOGO_DI_NASCITA[luogo],\r\n",
    "    \"eta\": lambda eta: ETA[eta], # cosa vuol dire eta?\r\n",
    "    \"codice_orario\": lambda _: np.nan, # unico dato: Mancante di sistema\r\n",
    "    \"freq_asilo_nido\": lambda frequenza: FREQUENZA_SCUOLA[frequenza],\r\n",
    "    \"freq_scuola_materna\": lambda frequenza: FREQUENZA_SCUOLA[frequenza],\r\n",
    "    \"luogo_padre\": lambda luogo: LUOGHI_GENITORI[luogo],\r\n",
    "    \"titolo_padre\": lambda titolo: TITOLI[titolo],\r\n",
    "    \"prof_padre\": lambda professione: PROFESSIONI[professione],\r\n",
    "    \"luogo_madre\": lambda luogo: LUOGHI_GENITORI[luogo],\r\n",
    "    \"titolo_madre\": lambda titolo: TITOLI[titolo],\r\n",
    "    \"prof_madre\": lambda professione: PROFESSIONI[professione],\r\n",
    "    \"voto_scritto_ita\": lambda voto: voto_scritto_decode(voto),\r\n",
    "    \"voto_orale_ita\": lambda voto: voto_orale_decode(voto),\r\n",
    "    \"voto_scritto_mat\": lambda voto: voto_scritto_decode(voto),\r\n",
    "    \"voto_orale_mat\": lambda voto: voto_orale_decode(voto),\r\n",
    "    \"D1\": lambda result: convert_question_result(result),\r\n",
    "    \"D2\": lambda result: convert_question_result(result),\r\n",
    "    \"D3_a\": lambda result: convert_question_result(result),\r\n",
    "    \"D3_b\": lambda result: convert_question_result(result),\r\n",
    "    \"D4_a\": lambda result: convert_question_result(result),\r\n",
    "    \"D4_b\": lambda result: convert_question_result(result),\r\n",
    "    \"D4_c\": lambda result: convert_question_result(result),\r\n",
    "    \"D4_d\": lambda result: convert_question_result(result),\r\n",
    "    \"D5_a\": lambda result: convert_question_result(result),\r\n",
    "    \"D5_b\": lambda result: convert_question_result(result),\r\n",
    "    \"D6\": lambda result: convert_question_result(result),\r\n",
    "    \"D7_a\": lambda result: convert_question_result(result),\r\n",
    "    \"D7_b\": lambda result: convert_question_result(result),\r\n",
    "    \"D8\": lambda result: convert_question_result(result),\r\n",
    "    \"D9\": lambda result: convert_question_result(result),\r\n",
    "    \"D10_a\": lambda result: convert_question_result(result),\r\n",
    "    \"D10_b1\": lambda result: convert_question_result(result),\r\n",
    "    \"D10_b2\": lambda result: convert_question_result(result),\r\n",
    "    \"D10_b3\": lambda result: convert_question_result(result),\r\n",
    "    \"D11_a\": lambda result: convert_question_result(result),\r\n",
    "    \"D11_b\": lambda result: convert_question_result(result),\r\n",
    "    \"D12_a\": lambda result: convert_question_result(result),\r\n",
    "    \"D12_b\": lambda result: convert_question_result(result),\r\n",
    "    \"D13_a\": lambda result: convert_question_result(result),\r\n",
    "    \"D13_b\": lambda result: convert_question_result(result),\r\n",
    "    \"D13_c\": lambda result: convert_question_result(result),\r\n",
    "    \"D14\": lambda result: convert_question_result(result),\r\n",
    "    \"D15\": lambda result: convert_question_result(result),\r\n",
    "    \"D16_a\": lambda result: convert_question_result(result),\r\n",
    "    \"D16_b\": lambda result: convert_question_result(result),\r\n",
    "    \"D16_c\": lambda result: convert_question_result(result),\r\n",
    "    \"D16_d\": lambda result: convert_question_result(result),\r\n",
    "    \"D17_a\": lambda result: convert_question_result(result),\r\n",
    "    \"D17_b\": lambda result: convert_question_result(result),\r\n",
    "    \"D18\": lambda result: convert_question_result(result),\r\n",
    "    \"D19_a\": lambda result: convert_question_result(result),\r\n",
    "    \"D19_b\": lambda result: convert_question_result(result),\r\n",
    "    \"D20\": lambda result: convert_question_result(result),\r\n",
    "    \"D21\": lambda result: convert_question_result(result),\r\n",
    "    \"D22\": lambda result: convert_question_result(result),\r\n",
    "    \"D23_a\": lambda result: convert_question_result(result),\r\n",
    "    \"D23_b\": lambda result: convert_question_result(result),\r\n",
    "    \"D23_c\": lambda result: convert_question_result(result),\r\n",
    "    \"D23_d\": lambda result: convert_question_result(result),\r\n",
    "    \"D24_a\": lambda result: convert_question_result(result),\r\n",
    "    \"D24_b\": lambda result: convert_question_result(result),\r\n",
    "    \"D25\": lambda result: convert_question_result(result),\r\n",
    "    \"D26_a\": lambda result: convert_question_result(result),\r\n",
    "    \"D26_b\": lambda result: convert_question_result(result),\r\n",
    "    \"D26_c\": lambda result: convert_question_result(result),\r\n",
    "    \"D26_d\": lambda result: convert_question_result(result),\r\n",
    "    \"regolarit√†\": lambda regular: REGOLARITA[regular],\r\n",
    "    \"cittadinanza\": lambda cittadinanza: CITTADINANZA[cittadinanza],\r\n",
    "    \"cod_provincia_ISTAT\": lambda province_istat: PROVINCE[province_istat.upper()],\r\n",
    "    \"sigla_provincia_istat\": lambda province: PROVINCE[province],\r\n",
    "    \"Nome_reg\": lambda regione: REGIONI[\" \".join(regione.split())],\r\n",
    "    \"Cod_reg\": lambda codice: REGIONI[codice],\r\n",
    "    \"Areageo_3\": lambda area: AREA_GEOGRAFICA_3[area],\r\n",
    "    \"Areageo_4\": lambda area: AREA_GEOGRAFICA_4[area],\r\n",
    "    \"Areageo_5\": lambda area: AREA_GEOGRAFICA_5[area],\r\n",
    "    \"Areageo_5_Istat\": lambda area: AREA_GEOGRAFICA_5_ISTAT[area],\r\n",
    "    \"Pon\": lambda pon: True if pon == \"Area_Pon\" else False, # lo studente appartiene all'aera Pon oppure no\r\n",
    "    \"pu_ma_gr\": int,\r\n",
    "    \"pu_ma_no\": float,\r\n",
    "    \"Fattore_correzione_new\": float,\r\n",
    "    \"Cheating\": float,\r\n",
    "    \"PesoClasse\": lambda val: float(val) if val != \"\" else np.nan, # (non considerato)\r\n",
    "    \"PesoScuola\": lambda val: float(val) if val != \"\" else np.nan, # (non considerato)\r\n",
    "    \"PesoTotale_Matematica\": lambda val: float(val) if val != \"\" else np.nan, # (non considerato)\r\n",
    "    \"WLE_MAT\": float,\r\n",
    "    \"WLE_MAT_200\": float,\r\n",
    "    \"WLE_MAT_200_CORR\": float,\r\n",
    "    \"pu_ma_no_corr\": float,\r\n",
    "    \"n_stud_prev\": lambda val: int(float(val)),\r\n",
    "    \"n_classi_prev\": lambda val: int(float(val)),\r\n",
    "    \"LIVELLI\": int,\r\n",
    "    \"DROPOUT\": eval\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "id": "mTqfUwl0erHM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lettura del dataset"
   ],
   "metadata": {
    "id": "Ef9Xh_mJfGPS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "if not from_azure:\r\n",
    "    dataset = pd.read_csv(DATASET_PATH, sep=';', converters=columns_converters)\r\n",
    "else:\r\n",
    "    from azureml.core import Workspace, Dataset\r\n",
    "    dataset = Dataset.get_by_name(workspace, name='invalsi_mat_2014')\r\n",
    "    dataset = dataset.to_pandas_dataframe()"
   ],
   "outputs": [],
   "metadata": {
    "id": "POdTrO5WfJpq"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Verifica per la presenza di variabili categoriche\n",
    "Oltre alle variabili categoriche fin qui trovate si vuole verificare quali discriminano in maniera non significativa le osservazioni."
   ],
   "metadata": {
    "id": "fqN-4pz_-lGw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "[dataset[c].dtype for c in dataset.columns if dataset[c].dtype not in ('float64', 'int64')]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('O'),\n",
       " dtype('bool')]"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# codice che restituisce le colonne che hanno un nr di valori distinti < 4\r\n",
    "[cname for cname in dataset.columns if dataset[cname].nunique() < 4 and dataset[cname].dtype != \"bool\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['macrotipologia',\n",
       " 'campione',\n",
       " 'livello',\n",
       " 'sesso',\n",
       " 'codice_orario',\n",
       " 'freq_asilo_nido',\n",
       " 'freq_scuola_materna',\n",
       " 'D1',\n",
       " 'D2',\n",
       " 'D3_a',\n",
       " 'D3_b',\n",
       " 'D4_a',\n",
       " 'D4_b',\n",
       " 'D4_c',\n",
       " 'D4_d',\n",
       " 'D5_a',\n",
       " 'D5_b',\n",
       " 'D6',\n",
       " 'D7_a',\n",
       " 'D7_b',\n",
       " 'D8',\n",
       " 'D9',\n",
       " 'D10_a',\n",
       " 'D10_b1',\n",
       " 'D10_b2',\n",
       " 'D10_b3',\n",
       " 'D11_a',\n",
       " 'D11_b',\n",
       " 'D12_a',\n",
       " 'D12_b',\n",
       " 'D13_a',\n",
       " 'D13_b',\n",
       " 'D13_c',\n",
       " 'D14',\n",
       " 'D15',\n",
       " 'D16_a',\n",
       " 'D16_b',\n",
       " 'D16_c',\n",
       " 'D16_d',\n",
       " 'D17_a',\n",
       " 'D17_b',\n",
       " 'D18',\n",
       " 'D19_a',\n",
       " 'D19_b',\n",
       " 'D20',\n",
       " 'D21',\n",
       " 'D22',\n",
       " 'D23_a',\n",
       " 'D23_b',\n",
       " 'D23_c',\n",
       " 'D23_d',\n",
       " 'D24_a',\n",
       " 'D24_b',\n",
       " 'D25',\n",
       " 'D26_a',\n",
       " 'D26_b',\n",
       " 'D26_c',\n",
       " 'D26_d',\n",
       " 'Areageo_3',\n",
       " 'Pon']"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vplCl4Nq2xLB",
    "outputId": "7605e5fb-3570-4ce9-f1db-d0d3a01bb1a3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# codice per ottenere le variabili qualitative/categoriche\r\n",
    "s = (dataset.dtypes == 'object')\r\n",
    "object_cols = list(s[s].index)\r\n",
    "\r\n",
    "print(\"Categorical variables:\")\r\n",
    "print(object_cols)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Categorical variables:\n",
      "['macrotipologia', 'sesso', 'mese', 'anno', 'luogo', 'eta', 'codice_orario', 'freq_asilo_nido', 'freq_scuola_materna', 'luogo_padre', 'titolo_padre', 'prof_padre', 'luogo_madre', 'titolo_madre', 'prof_madre', 'voto_scritto_ita', 'voto_orale_ita', 'voto_scritto_mat', 'voto_orale_mat', 'D1', 'D2', 'D3_a', 'D3_b', 'D4_a', 'D4_b', 'D4_c', 'D4_d', 'D5_a', 'D5_b', 'D6', 'D7_a', 'D7_b', 'D8', 'D9', 'D10_a', 'D10_b1', 'D10_b2', 'D10_b3', 'D11_a', 'D11_b', 'D12_a', 'D12_b', 'D13_a', 'D13_b', 'D13_c', 'D14', 'D15', 'D16_a', 'D16_b', 'D16_c', 'D16_d', 'D17_a', 'D17_b', 'D18', 'D19_a', 'D19_b', 'D20', 'D21', 'D22', 'D23_a', 'D23_b', 'D23_c', 'D23_d', 'D24_a', 'D24_b', 'D25', 'D26_a', 'D26_b', 'D26_c', 'D26_d', 'regolarit√†', 'cittadinanza', 'cod_provincia_ISTAT', 'sigla_provincia_istat', 'Nome_reg', 'Cod_reg', 'Areageo_3', 'Areageo_4', 'Areageo_5', 'Areageo_5_Istat', 'Pon']\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zxGS6Cq14Xjc",
    "outputId": "d6a1ae51-5ad1-41de-9e6f-18641ed6ed33"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Eliminazione colonne superflue\n",
    "Vengono rimosse dal dataset originale tutte quegli attributi che si suppone non abbiano alcuna rilevanza nell'esito della cella DROPOUT.\n",
    "Inoltre, per la compuntazione del clustering ai fini dell'oversampling √® necessario rimuovere degli ulteriori attributi poich√© ricchi di valori nulli e quindi problematici.\n"
   ],
   "metadata": {
    "id": "kAMeln9J19au"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "columns_to_drop = (\"Unnamed: 0\" if not from_azure else []) + [\"CODICE_SCUOLA\",\r\n",
    "                   \"CODICE_PLESSO\",\r\n",
    "                   \"CODICE_CLASSE\",\r\n",
    "                   \"macrotipologia\",\r\n",
    "                   \"campione\",\r\n",
    "                   \"livello\",\r\n",
    "                   \"CODICE_STUDENTE\",\r\n",
    "                   \"codice_orario\",\r\n",
    "                   \"PesoClasse\", # potrebbe essere utile?\r\n",
    "                   \"PesoScuola\", # potrebbe essere utile?\r\n",
    "                   \"PesoTotale_Matematica\", # potrebbe essere utile?\r\n",
    "                   ]\r\n",
    "columns_maybe_to_drop = [\"voto_scritto_ita\", #Ricco di NaN\r\n",
    "                         \"voto_scritto_mat\",#Ricco di NaN\r\n",
    "                         \"voto_orale_ita\", # Pochi NaN ma va tolto per cluster-based oversampling\r\n",
    "                         \"voto_orale_mat\" # Pochi NaN ma va tolto per cluster-based oversampling\r\n",
    "                        ]\r\n",
    "for col in columns_maybe_to_drop:\r\n",
    "   print(\"Percentage of NaN in column: \", col, end=\" \")\r\n",
    "   print(round(dataset[col].isnull().mean() * 100, 2), \"%\")\r\n",
    "   \r\n",
    "dataset = dataset.drop(columns_to_drop + columns_maybe_to_drop, axis=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percentage of NaN in column:  voto_scritto_ita 0.0 %\n",
      "Percentage of NaN in column:  voto_scritto_mat 0.0 %\n",
      "Percentage of NaN in column:  voto_orale_ita 0.0 %\n",
      "Percentage of NaN in column:  voto_orale_mat 0.0 %\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Matrici correlazione tra domande\n",
    "Con le seguenti matrici di correlazione si cerca di vedere se sono presenti domande fortemente correlate in modo da poterne rimuovere e semplificare una riduzione di dimensionalit√†."
   ],
   "metadata": {
    "id": "j3YeO8Ycfx7u"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "questions_columns = [col for col in columns_converters.keys() if re.search(\"^D\\d\", col)]\r\n",
    "questions_dataset = dataset[questions_columns]"
   ],
   "outputs": [],
   "metadata": {
    "id": "6EqG0d5Mf2CO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Standard correlation coefficient (pearson method)"
   ],
   "metadata": {
    "id": "RNEbExY6gQcu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "questions_correlate_matrix_pearson = questions_dataset.corr(method='pearson').round(2)\r\n",
    "questions_correlate_matrix_pearson.style.background_gradient(cmap='YlOrRd')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff02e8dd0b8>"
      ],
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_53e5258a_eaf3_11eb_88d0_bba8819819dc\" ><thead></thead><tbody>\n",
       "        </tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {
    "id": "pe416QwMgJ6U",
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "089651b3-372b-483e-dd66-057f899d676e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Kendall Tau correlation coefficient"
   ],
   "metadata": {
    "id": "ABgGSd1tgYej"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "questions_correlate_matrix_kendall = questions_dataset.corr(method='kendall').round(2)\r\n",
    "questions_correlate_matrix_kendall.style.background_gradient(cmap='YlOrRd')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff0b4189e10>"
      ],
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_576711a0_eaf3_11eb_88d0_bba8819819dc\" ><thead></thead><tbody>\n",
       "        </tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {
    "id": "VN09a_kCgNe0",
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "37772628-1fd0-4343-e7cc-7bbb8efda5e9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spearman rank correlation"
   ],
   "metadata": {
    "id": "e7wAdEsKgkvg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "questions_correlate_matrix_spearman = questions_dataset.corr(method='spearman').round(2)\r\n",
    "questions_correlate_matrix_spearman.style.background_gradient(cmap='YlOrRd')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff02dc21710>"
      ],
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_58976bc4_eaf3_11eb_88d0_bba8819819dc\" ><thead></thead><tbody>\n",
       "        </tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {
    "id": "gKUli2aEgfZ5",
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "8947f2dd-0cf9-4646-bde7-ce8eff0005df"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Nota sulle matrici di correlazione ottenute\n",
    "Le **matrici di correlazione sulle domande** non evidenziano significative dipendenze lineari tra di esse: i valori pi√π elevati appaiono in corrispondenza di domande consecutive, il pi√π delle volte parti della stessa domanda (e.g. D7, D3 e D4).  \n",
    "Conseguentemente, **non √® possibile realizzare alcuna riduzione di dimensionalit√†**."
   ],
   "metadata": {
    "id": "JBU9svIjbD9t"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rappresentazione delle domande per generalizzazione con coorti diverse\n",
    "Addestrando la rete con le domande non si ottiene nulla di replicabili in coorti successive.\n",
    "E' possibile per√≤ trasformare le domande e i risultati dati dagli studenti in altre feature. Ogni domanda dispone infatti di un ambito, uno scopo e un processo.  \n",
    "Per questo motivo le domande vengono trasformate in due modalit√†:\n",
    "\n",
    "- da domanda a coppia ambito - processo;\n",
    "- da domanda a vettore di termini chiave  estratti tramite Natural Language Processing dallo scopo."
   ],
   "metadata": {
    "id": "rsdodsx-2kGV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generalizzazione Domanda => (Ambito, Processo)"
   ],
   "metadata": {
    "id": "v2LLlA3bC0w8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# mapping domanda - ambito, processo\r\n",
    "questions_ambiti_processi = {\r\n",
    "    'D1' : ('Numeri', 'Conoscere e utilizzare algoritmi e procedure'),\r\n",
    "    'D2' : ('Dati e previsioni', 'Conoscere e padroneggiare i contenuti specifici della matematica'),\r\n",
    "    'D3_a' : ('Dati e previsioni', 'Utilizzare strumenti, modelli e rappresentazioni nel trattamento quantitativo dell\\'informazione in ambito scientifico, tecnologico, economico e sociale'),\r\n",
    "    'D3_b': ('Numeri', 'Conoscere e utilizzare algoritmi e procedure'),\r\n",
    "    'D4_a' : ('Spazio figure', 'Riconoscere le forme nello spazio e utilizzarle per la risoluzione di problemi geometrici o di modellizzazione'),\r\n",
    "    'D4_b' : ('Spazio figure', 'Riconoscere le forme nello spazio e utilizzarle per la risoluzione di problemi geometrici o di modellizzazione'),\r\n",
    "    'D4_c' : ('Spazio figure', 'Riconoscere le forme nello spazio e utilizzarle per la risoluzione di problemi geometrici o di modellizzazione'),\r\n",
    "    'D4_d' : ('Spazio figure', 'Riconoscere le forme nello spazio e utilizzarle per la risoluzione di problemi geometrici o di modellizzazione'),\r\n",
    "    'D5_a' : ('Relazioni e funzioni', 'Conoscere e utilizzare algoritmi e procedure'),\r\n",
    "    'D5_b' : ('Relazioni e funzioni', 'Utilizzare strumenti, modelli e rappresentazioni nel trattamento quantitativo dell\\'informazione in ambito scientifico, tecnologico, economico e sociale'),\r\n",
    "    'D6' : ('Numeri', 'Acquisire progressivamente forme tipiche del pensiero matematico'),\r\n",
    "    'D7_a' : ('Numeri', 'Conoscere e padroneggiare i contenuti specifici della matematica'),\r\n",
    "    'D7_b' : ('Numeri', 'Conoscere e padroneggiare i contenuti specifici della matematica'),\r\n",
    "    'D8' : ('Spazio figure', 'Riconoscere le forme nello spazio e utilizzarle per la risoluzione di problemi geometrici o di modellizzazione'),\r\n",
    "    'D9' : ('Relazioni e funzioni', 'Utilizzare strumenti, modelli e rappresentazioni nel trattamento quantitativo dell\\'informazione in ambito scientifico, tecnologico, economico e sociale'),\r\n",
    "    'D10_a'  : ('Relazioni e funzioni', 'Rappresentare relazioni e dati e, in situazioni significative, utilizzare le rappresentazioni per ricavare informazioni, formulare giudizi e prendere decisioni'),\r\n",
    "    'D10_b1' : ('Relazioni e funzioni', 'Rappresentare relazioni e dati e, in situazioni significative, utilizzare le rappresentazioni per ricavare informazioni, formulare giudizi e prendere decisioni'),\r\n",
    "    'D10_b2' : ('Relazioni e funzioni', 'Rappresentare relazioni e dati e, in situazioni significative, utilizzare le rappresentazioni per ricavare informazioni, formulare giudizi e prendere decisioni'),\r\n",
    "    'D10_b3' : ('Relazioni e funzioni', 'Rappresentare relazioni e dati e, in situazioni significative, utilizzare le rappresentazioni per ricavare informazioni, formulare giudizi e prendere decisioni'),\r\n",
    "    'D11_a' : ('Spazio figure', 'Riconoscere in contesti diversi il carattere misurabile di oggetti e fenomeni, utilizzare strumenti di misura, misurare grandezze, stimare misure di grandezze'),\r\n",
    "    'D11_b' : ('Spazio figure', 'Conoscere e utilizzare algoritmi e procedure'),\r\n",
    "    'D12_a' : ('Numeri', 'Risolvere problemi utilizzando strategie in ambiti diversi ‚Äì numerico, geometrico, algebrico ‚Äì'),\r\n",
    "    'D12_b' : ('Numeri', 'Risolvere problemi utilizzando strategie in ambiti diversi ‚Äì numerico, geometrico, algebrico ‚Äì'),\r\n",
    "    'D13_a' : ('Dati e previsioni', 'Utilizzare strumenti, modelli e rappresentazioni nel trattamento quantitativo dell\\'informazione in ambito scientifico, tecnologico, economico e sociale'),\r\n",
    "    'D13_b' : ('Dati e previsioni', 'Utilizzare strumenti, modelli e rappresentazioni nel trattamento quantitativo dell\\'informazione in ambito scientifico, tecnologico, economico e sociale'),\r\n",
    "    'D13_c' : ('Dati e previsioni', 'Utilizzare strumenti, modelli e rappresentazioni nel trattamento quantitativo dell\\'informazione in ambito scientifico, tecnologico, economico e sociale'),\r\n",
    "    'D14' : ('Relazioni e funzioni', 'Acquisire progressivamente forme tipiche del pensiero matematico'),\r\n",
    "    'D15' : ('Dati e previsioni', 'Conoscere e utilizzare algoritmi e procedure'),\r\n",
    "    'D16_a' : ('Dati e previsioni', 'Utilizzare strumenti, modelli e rappresentazioni nel trattamento quantitativo dell\\'informazione in ambito scientifico, tecnologico, economico e sociale'),\r\n",
    "    'D16_b' : ('Dati e previsioni', 'Utilizzare strumenti, modelli e rappresentazioni nel trattamento quantitativo dell\\'informazione in ambito scientifico, tecnologico, economico e sociale'),\r\n",
    "    'D16_c' : ('Dati e previsioni', 'Utilizzare strumenti, modelli e rappresentazioni nel trattamento quantitativo dell\\'informazione in ambito scientifico, tecnologico, economico e sociale'),\r\n",
    "    'D16_d' : ('Dati e previsioni', 'Utilizzare strumenti, modelli e rappresentazioni nel trattamento quantitativo dell\\'informazione in ambito scientifico, tecnologico, economico e sociale'),\r\n",
    "    'D17_a' : ('Numeri', 'Riconoscere in contesti diversi il carattere misurabile di oggetti e fenomeni, utilizzare strumenti di misura, misurare grandezze, stimare misure di grandezze'),\r\n",
    "    'D17_b' : ('Numeri', 'Riconoscere in contesti diversi il carattere misurabile di oggetti e fenomeni, utilizzare strumenti di misura, misurare grandezze, stimare misure di grandezze'),\r\n",
    "    'D18' : ('Spazio figure', 'Conoscere e utilizzare algoritmi e procedure'),\r\n",
    "    'D19_a' : ('Spazio figure', 'Risolvere problemi utilizzando strategie in ambiti diversi ‚Äì numerico, geometrico, algebrico ‚Äì'),\r\n",
    "    'D19_b' : ('Spazio figure', 'Risolvere problemi utilizzando strategie in ambiti diversi ‚Äì numerico, geometrico, algebrico ‚Äì'),\r\n",
    "    'D20' : ('Dati e previsioni', 'Conoscere e utilizzare algoritmi e procedure'),\r\n",
    "    'D21' : ('Numeri', 'Riconoscere in contesti diversi il carattere misurabile di oggetti e fenomeni, utilizzare strumenti di misura, misurare grandezze, stimare misure di grandezze'),\r\n",
    "    'D22' : ('Spazio figure', 'Acquisire progressivamente forme tipiche del pensiero matematico'),\r\n",
    "    'D23_a' : ('Relazioni e funzioni', 'Acquisire progressivamente forme tipiche del pensiero matematico'),\r\n",
    "    'D23_b' : ('Relazioni e funzioni', 'Acquisire progressivamente forme tipiche del pensiero matematico'),\r\n",
    "    'D23_c' : ('Relazioni e funzioni', 'Acquisire progressivamente forme tipiche del pensiero matematico'),\r\n",
    "    'D23_d' : ('Relazioni e funzioni', 'Acquisire progressivamente forme tipiche del pensiero matematico'),\r\n",
    "    'D24_a' : ('Relazioni e funzioni', 'Conoscere e padroneggiare i contenuti specifici della matematica'),\r\n",
    "    'D24_b' : ('Relazioni e funzioni', 'Utilizzare strumenti, modelli e rappresentazioni nel trattamento quantitativo dell\\'informazione in ambito scientifico, tecnologico, economico e sociale'),\r\n",
    "    'D25' : ('Spazio figure', 'Conoscere e utilizzare algoritmi e procedure'),\r\n",
    "    'D26_a': ('Numeri', 'Conoscere e padroneggiare i contenuti specifici della matematica'),\r\n",
    "    'D26_b': ('Numeri', 'Conoscere e padroneggiare i contenuti specifici della matematica'),\r\n",
    "    'D26_c': ('Numeri', 'Conoscere e padroneggiare i contenuti specifici della matematica'),\r\n",
    "    'D26_d': ('Numeri', 'Conoscere e padroneggiare i contenuti specifici della matematica')\r\n",
    "}\r\n",
    "\r\n",
    "list_ambiti_processi = [AP for dom in questions_ambiti_processi.values() for AP in dom]\r\n",
    "ambiti_processi = set(list_ambiti_processi)\r\n",
    "conteggio_ambiti_processi = {AP: list_ambiti_processi.count(AP) for AP in ambiti_processi}\r\n",
    "\r\n",
    "for AP in ambiti_processi:\r\n",
    "    dataset[AP] = 0.0\r\n",
    "\r\n",
    "for i, row in dataset.iterrows():\r\n",
    "    for question, APs in questions_ambiti_processi.items():\r\n",
    "        if row[question] == True:\r\n",
    "            for AP in APs:\r\n",
    "                dataset.at[i, AP] += 1/conteggio_ambiti_processi[AP]\r\n",
    "\r\n",
    "dataset = dataset.drop(questions_columns, axis=1)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "yUB0DaHnzePw",
    "outputId": "fc64e8ff-a67a-446f-b848-13b60bc29c9a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "if not from_azure:\r\n",
    "    if from_gdrive:\r\n",
    "        AP_DATASET_PATH = \"Data/dataset_with_AP/dataset_with_AP.csv\"\r\n",
    "    else:\r\n",
    "        AP_DATASET_PATH = \"../dataset_with_AP/dataset_with_AP.csv\" \r\n",
    "\r\n",
    "    dataset = pd.read_csv(AP_DATASET_PATH, sep=',')\r\n",
    "\r\n",
    "    dataset['DROPOUT'] = dataset['DROPOUT'].astype('int64')\r\n",
    "    dataset['Pon'] = dataset['Pon'].astype('int64')\r\n",
    "    dataset['sesso'] = dataset['sesso'].astype('int64')\r\n",
    "else:\r\n",
    "    from azureml.core import Workspace, Dataset\r\n",
    "    dataset = Dataset.get_by_name(workspace, name='dataset_with_AP')\r\n",
    "    dataset = dataset.to_pandas_dataframe()"
   ],
   "outputs": [],
   "metadata": {
    "id": "sriI349OIvW0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generalizzazione Domanda => termini chiave da Scopo"
   ],
   "metadata": {
    "id": "6gKlTKS_CqfF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split dataset in training, validation e test\n",
    "Avendo un dataset di una sola coorte di studenti relativi alle prove di un anno, non si dispone di un set per fare testing.\n",
    "Per questo motivo si √® scelto di separare il dataset in questo modo:\n",
    "\n",
    "1. dataset diviso in train_dataset (80%) e test_dataset (20%)\n",
    "2. train_dataset diviso in train_dataset (80%) e validation_dataset (20%)"
   ],
   "metadata": {
    "id": "x4rVw_SqFdPe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2)\r\n",
    "train_dataset, validation_dataset = train_test_split(train_dataset, test_size=0.2)"
   ],
   "outputs": [],
   "metadata": {
    "id": "YK77ZxFOFjpS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Valutazione e gestione dello sbilanciamento del dataset"
   ],
   "metadata": {
    "id": "Ce0xEolbKOeQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "nr_nodrop_original, nr_drop_original = np.bincount(dataset['DROPOUT'])\r\n",
    "nr_nodrop, nr_drop = np.bincount(train_dataset['DROPOUT'])\r\n",
    "total_original = nr_nodrop_original + nr_drop_original\r\n",
    "total = nr_nodrop + nr_drop\r\n",
    "print('Dataset originale')\r\n",
    "print(f'Nr di istanze: {total_original:,}\\nIstanze con dropout a True: {nr_nodrop_original:,} ({(100 * nr_nodrop_original / total_original):.2f}% del totale)\\nProporzione dropout True v/s False: {round(nr_drop_original/nr_nodrop_original, 2)} : 1')\r\n",
    "print('Training dataset')\r\n",
    "print(f'Nr di istanze: {total:,}\\nIstanze con dropout a True: {nr_drop:,} ({(100 * nr_drop / total):.2f}% del totale)\\nProporzione dropout True v/s False: {round(nr_drop/nr_nodrop, 2)} : 1')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'NoneType'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-237223f03340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnr_nodrop_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnr_drop_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DROPOUT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnr_nodrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnr_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DROPOUT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtotal_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnr_nodrop_original\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnr_drop_original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnr_nodrop\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnr_drop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataset originale'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbincount\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"M8[ns]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/arrays/numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'NoneType'"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SM8tXExZKaF7",
    "outputId": "7a97fb6e-6881-4e4d-a6d7-0166f98900c0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sbilanciamento dataset originale"
   ],
   "metadata": {
    "id": "AEoSFlmxE-q2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = pd.Series([nr_nodrop_original, nr_drop_original])\r\n",
    "data.plot.pie(autopct=\"%.1f%%\");"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "Cnn9VuBDFG85",
    "outputId": "e7811bc7-1453-4702-a832-ea1e9ebf761f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sbilanciamento dataset di training"
   ],
   "metadata": {
    "id": "TG-fa363FCSK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = pd.Series([nr_nodrop, nr_drop])\r\n",
    "data.plot.pie(autopct=\"%.1f%%\");"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "tR5LJ8RUl9LL",
    "outputId": "c1af3f78-932a-4cf9-dfbd-f4c4ad0abffa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le due classi (i.e. target del classificatore) appaiono leggermente sbilanciate: in dettaglio, la classe dei soggetti che manifestano dropout ha una cardinalit√† inferiore della classe in cui non si √® avuto dropout."
   ],
   "metadata": {
    "id": "ZJN0Q8UzdGlV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random under-sampling\n",
    "Tecnica consistente nell'eliminazione in maniera randomica di istanze della classe sovra-rappresentata (studenti che non hanno avuto un dropout) fintanto che la sua cardinalit√† coincida con quella della classe sotto-rappresentata."
   ],
   "metadata": {
    "id": "6m6aNeE6kZZI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class_nodrop = train_dataset[train_dataset['DROPOUT'] == False] # Sovrarappresentata\r\n",
    "class_drop = train_dataset[train_dataset['DROPOUT'] == True] # Sottorappresentata\r\n",
    "\r\n",
    "# Sotto campionamento di class_drop in modo che abbia stessa cardinalit√† di class_nodrop\r\n",
    "class_nodrop = class_nodrop.sample(len(class_drop))\r\n",
    "\r\n",
    "print(f'Classe No-drop: {len(class_nodrop):,}')\r\n",
    "print(f'Classe Drop: {len(class_drop):,}')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vi9UK1Jkkb_X",
    "outputId": "526c7cba-24c7-45e5-c504-53468c137856"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Il dataset di training va aggiornato unendo i due class_drop e class_nodrop\r\n",
    "print(f'Dimensioni train_dataset originale: {train_dataset.shape}')\r\n",
    "train_dataset = class_drop.append(class_nodrop)\r\n",
    "print(f'Dimensioni train_dataset undersampled: {train_dataset.shape}')"
   ],
   "outputs": [],
   "metadata": {
    "id": "o7ZLgOb1KI0h",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1ac588d7-8d13-4707-f096-f2b624be4106"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Verifica che effettivamente l'undersampling abbia funzionato\r\n",
    "nr_nodrop, nr_drop = np.bincount(train_dataset['DROPOUT'])\r\n",
    "data = pd.Series([nr_nodrop, nr_drop])\r\n",
    "data.plot.pie(autopct=\"%.1f%%\");"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "r6H6sPzn5DsX",
    "outputId": "d36010cc-05cf-4a9e-a7d8-06373d750acc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Synthetic minority over-sampling (SMOTE)\n",
    "Abbiamo scelto di tentare la variante della tecnica dell'over-sampling come alternativa al random under-sampling, in quanto permette di evitare la riduzione di cardinalit√† del training set che inevitabilmente segue al random under-sampling.\n",
    "\n",
    "\n",
    "VAI MICHELE SCELGO TE\n"
   ],
   "metadata": {
    "id": "9p59HqO4MAfg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# La seguente cella non riesce ad eseguire in Google Colab (finisce la memoria e riavvia il runtime).\r\n",
    "# I risultati di questa cella sono stati calcolati localmente e salvati su un dataset CSV che √® possibile importare grazie alle cella seguente.\r\n",
    "# Imports\r\n",
    "from imblearn.over_sampling import SMOTENC\r\n",
    "\r\n",
    "# Create KMeans-Random instance\r\n",
    "categorical_features_indexes = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]\r\n",
    "smotenc = SMOTENC(categorical_features_indexes, random_state=19, n_jobs=-1)\r\n",
    "\r\n",
    "# Fit and resample imbalanced dataa\r\n",
    "X_SMOTE = train_dataset.loc[:, train_dataset.columns != 'DROPOUT']\r\n",
    "y_SMOTE = train_dataset['DROPOUT']\r\n",
    "X_SMOTE_res, y_SMOTE_res = smotenc.fit_resample(X_SMOTE, y_SMOTE)\r\n",
    "\r\n",
    "no_drop, drop = np.bincount(y_SMOTE['DROPOUT'])\r\n",
    "res_no_drop, res_drop = np.bincount(y_SMOTE_res['DROPOUT'])\r\n",
    "\r\n",
    "print(f'Classe No-drop originale: {len(no_drop):,} - Classe No-drop ricampionata: {len(res_no_drop):,}')\r\n",
    "print(f'Classe Drop originale: {len(drop):,} - Classe Drop ricampionata: {len(res_drop):,}')"
   ],
   "outputs": [],
   "metadata": {
    "id": "v3uTh1BpOxjt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if from_gdrive:\r\n",
    "    RESAMPLED_DATASET_PATH = \"Data/resampled_training_dataset.csv\"\r\n",
    "else:\r\n",
    "    RESAMPLED_DATASET_PATH = \"../resampled_training_dataset.csv\" \r\n",
    "\r\n",
    "resampled_train_dataset = pd.read_csv(RESAMPLED_DATASET_PATH, sep=',')"
   ],
   "outputs": [],
   "metadata": {
    "id": "xpizgu1keGmC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nr_nodrop_sample, nr_drop_sample = np.bincount(resampled_train_dataset['DROPOUT'])\r\n",
    "total_sample = nr_nodrop_sample + nr_drop_sample\r\n",
    "print(f'Nr di istanze: {total_sample:,}\\nIstanze con dropout a True: {nr_drop_sample:,} ({(100 * nr_drop_sample / total_sample):.2f}% del totale)\\nProporzione dropout True v/s False: {round(nr_drop_sample/nr_nodrop_sample, 2)} : 1')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOAilk3Kgy--",
    "outputId": "0d121209-48de-43c2-b844-1b0ec8e5357b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = pd.Series([nr_nodrop_sample, nr_drop_sample])\r\n",
    "data.plot.pie(autopct=\"%.1f%%\");"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "YAVimNfAhgFG",
    "outputId": "69518175-9b4c-4fa5-a90f-139a0cdd60b0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Architettura rete neurale"
   ],
   "metadata": {
    "id": "Xa9b5de8aDtf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Conversione del dataframe di Pandas nel tensore "
   ],
   "metadata": {
    "id": "9oLyHxpuhU7g"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def dataframe_to_dataset(dataframe):\r\n",
    "    dataframe = dataframe.copy()\r\n",
    "    labels = dataframe.pop(\"DROPOUT\")\r\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\r\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\r\n",
    "    return ds\r\n",
    "\r\n",
    "\r\n",
    "train_ds = dataframe_to_dataset(train_dataset)\r\n",
    "val_ds = dataframe_to_dataset(validation_dataset)\r\n",
    "test_ds = dataframe_to_dataset(test_dataset)"
   ],
   "outputs": [],
   "metadata": {
    "id": "egzMbPotaHo-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for x, y in train_ds.take(1):\r\n",
    "    print(\"Input:\", x)\r\n",
    "    print(\"Target:\", y)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7CcmWCLYhuYQ",
    "outputId": "978af593-4a0b-4f4c-c757-501852718e35"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_ds = train_ds.batch(32)\r\n",
    "val_ds = val_ds.batch(32)"
   ],
   "outputs": [],
   "metadata": {
    "id": "xRLJH5n8iNKh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import IntegerLookup\r\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\r\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\r\n",
    "\r\n",
    "\r\n",
    "def encode_numerical_feature(feature, name, dataset):\r\n",
    "    # Create a Normalization layer for our feature\r\n",
    "    normalizer = Normalization()\r\n",
    "\r\n",
    "    # Prepare a Dataset that only yields our feature\r\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\r\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\r\n",
    "\r\n",
    "    # Learn the statistics of the data\r\n",
    "    normalizer.adapt(feature_ds)\r\n",
    "\r\n",
    "    # Normalize the input feature\r\n",
    "    encoded_feature = normalizer(feature)\r\n",
    "    return encoded_feature\r\n",
    "\r\n",
    "\r\n",
    "def encode_categorical_feature(feature, name, dataset, is_string):\r\n",
    "    lookup_class = StringLookup if is_string else IntegerLookup\r\n",
    "    # Create a lookup layer which will turn strings into integer indices\r\n",
    "    lookup = lookup_class(output_mode=\"binary\")\r\n",
    "\r\n",
    "    # Prepare a Dataset that only yields our feature\r\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\r\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\r\n",
    "\r\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\r\n",
    "    lookup.adapt(feature_ds)\r\n",
    "\r\n",
    "    # Turn the string input into integer indices\r\n",
    "    encoded_feature = lookup(feature)\r\n",
    "    return encoded_feature\r\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "rexYr65kilq-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Categorical features encoded as integers\r\n",
    "prog = keras.Input(shape=(1,), name=\"prog\", dtype=\"int64\")\r\n",
    "mese = keras.Input(shape=(1,), name=\"mese\", dtype=\"int64\")\r\n",
    "anno = keras.Input(shape=(1,), name=\"anno\", dtype=\"int64\")\r\n",
    "luogo = keras.Input(shape=(1,), name=\"luogo\", dtype=\"int64\")\r\n",
    "eta = keras.Input(shape=(1,), name=\"eta\", dtype=\"int64\")\r\n",
    "freq_asilo_nido = keras.Input(shape=(1,), name=\"freq_asilo_nido\", dtype=\"int64\")\r\n",
    "freq_scuola_materna = keras.Input(shape=(1,), name=\"freq_scuola_materna\", dtype=\"int64\")\r\n",
    "luogo_padre = keras.Input(shape=(1,), name=\"luogo_padre\", dtype=\"int64\")\r\n",
    "titolo_padre = keras.Input(shape=(1,), name=\"titolo_padre\", dtype=\"int64\")\r\n",
    "prof_padre = keras.Input(shape=(1,), name=\"prof_padre\", dtype=\"int64\")\r\n",
    "luogo_madre = keras.Input(shape=(1,), name=\"luogo_madre\", dtype=\"int64\")\r\n",
    "titolo_madre = keras.Input(shape=(1,), name=\"titolo_madre\", dtype=\"int64\")\r\n",
    "prof_madre = keras.Input(shape=(1,), name=\"prof_madre\", dtype=\"int64\")\r\n",
    "regolarit√† = keras.Input(shape=(1,), name=\"regolarit√†\", dtype=\"int64\")\r\n",
    "cittadinanza = keras.Input(shape=(1,), name=\"cittadinanza\", dtype=\"int64\")\r\n",
    "cod_provincia_ISTAT = keras.Input(shape=(1,), name=\"cod_provincia_ISTAT\", dtype=\"int64\")\r\n",
    "sigla_provincia_istat = keras.Input(shape=(1,), name=\"sigla_provincia_istat\", dtype=\"int64\")\r\n",
    "Nome_reg = keras.Input(shape=(1,), name=\"Nome_reg\", dtype=\"int64\")\r\n",
    "Cod_reg = keras.Input(shape=(1,), name=\"Cod_reg\", dtype=\"int64\")\r\n",
    "Areageo_3 = keras.Input(shape=(1,), name=\"Areageo_3\", dtype=\"int64\")\r\n",
    "Areageo_4 = keras.Input(shape=(1,), name=\"Areageo_4\", dtype=\"int64\")\r\n",
    "Areageo_5 = keras.Input(shape=(1,), name=\"Areageo_5\", dtype=\"int64\")\r\n",
    "Areageo_5_Istat = keras.Input(shape=(1,), name=\"Areageo_5_Istat\", dtype=\"int64\")\r\n",
    "LIVELLI = keras.Input(shape=(1,), name=\"LIVELLI\", dtype=\"int64\")\r\n",
    "pu_ma_gr = keras.Input(shape=(1,), name=\"pu_ma_gr\", dtype=\"float32\")\r\n",
    "\r\n",
    "sesso = keras.Input(shape=(1,), name=\"sesso\", dtype=\"int64\")\r\n",
    "Pon = keras.Input(shape=(1,), name=\"Pon\", dtype=\"int64\")\r\n",
    "\r\n",
    "# Numerical features\r\n",
    "pu_ma_gr = keras.Input(shape=(1,), name=\"pu_ma_gr\")\r\n",
    "pu_ma_no = keras.Input(shape=(1,), name=\"pu_ma_no\")\r\n",
    "Fattore_correzione_new = keras.Input(shape=(1,), name=\"Fattore_correzione_new\")\r\n",
    "Cheating = keras.Input(shape=(1,), name=\"Cheating\")\r\n",
    "WLE_MAT = keras.Input(shape=(1,), name=\"WLE_MAT\")\r\n",
    "WLE_MAT_200 = keras.Input(shape=(1,), name=\"WLE_MAT_200\")\r\n",
    "WLE_MAT_200_CORR = keras.Input(shape=(1,), name=\"WLE_MAT_200_CORR\")\r\n",
    "pu_ma_no_corr = keras.Input(shape=(1,), name=\"pu_ma_no_corr\")\r\n",
    "n_stud_prev = keras.Input(shape=(1,), name=\"n_stud_prev\")\r\n",
    "Numeri = keras.Input(shape=(1,), name=\"Numeri\")\r\n",
    "n_classi_prev = keras.Input(shape=(1,), name=\"n_classi_prev\")\r\n",
    "Dati = keras.Input(shape=(1,), name=\"Dati e previsioni\")\r\n",
    "Riconoscere_forme = keras.Input(shape=(1,), name=\"Riconoscere le forme nello spazio e utilizzarle per la risoluzione di problemi geometrici o di modellizzazione\")\r\n",
    "Conoscere_padr = keras.Input(shape=(1,), name=\"Conoscere e padroneggiare i contenuti specifici della matematica\")\r\n",
    "Relazioni = keras.Input(shape=(1,), name=\"Relazioni e funzioni\")\r\n",
    "Spazio = keras.Input(shape=(1,), name=\"Spazio figure\")\r\n",
    "Acquisire = keras.Input(shape=(1,), name=\"Acquisire progressivamente forme tipiche del pensiero matematico\")\r\n",
    "Conoscere_util = keras.Input(shape=(1,), name=\"Conoscere e utilizzare algoritmi e procedure\")\r\n",
    "Rappresentare = keras.Input(shape=(1,), name=\"Rappresentare relazioni e dati e, in situazioni significative, utilizzare le rappresentazioni per ricavare informazioni, formulare giudizi e prendere decisioni\")\r\n",
    "Riconoscere_contesti = keras.Input(shape=(1,), name=\"Riconoscere in contesti diversi il carattere misurabile di oggetti e fenomeni, utilizzare strumenti di misura, misurare grandezze, stimare misure di grandezze\")\r\n",
    "Risolvere = keras.Input(shape=(1,), name=\"Risolvere problemi utilizzando strategie in ambiti diversi ‚Äì numerico, geometrico, algebrico ‚Äì\")\r\n",
    "Utilizzare = keras.Input(shape=(1,), name=\"Utilizzare strumenti, modelli e rappresentazioni nel trattamento quantitativo dell'informazione in ambito scientifico, tecnologico, economico e sociale\")\r\n",
    "\r\n",
    "all_inputs = [\r\n",
    "    prog, \r\n",
    "    sesso, \r\n",
    "    mese, \r\n",
    "    anno, \r\n",
    "    luogo, \r\n",
    "    eta, \r\n",
    "    freq_asilo_nido, \r\n",
    "    freq_scuola_materna, \r\n",
    "    luogo_padre, \r\n",
    "    titolo_padre, \r\n",
    "    prof_padre, \r\n",
    "    luogo_madre, \r\n",
    "    titolo_madre, \r\n",
    "    prof_madre, \r\n",
    "    regolarit√†, \r\n",
    "    cittadinanza, \r\n",
    "    cod_provincia_ISTAT, \r\n",
    "    sigla_provincia_istat, \r\n",
    "    Nome_reg, \r\n",
    "    Cod_reg, \r\n",
    "    Areageo_3, \r\n",
    "    Areageo_4, \r\n",
    "    Areageo_5, \r\n",
    "    Areageo_5_Istat, \r\n",
    "    Pon, \r\n",
    "    pu_ma_gr, \r\n",
    "    pu_ma_no, \r\n",
    "    Fattore_correzione_new, \r\n",
    "    Cheating, \r\n",
    "    WLE_MAT, \r\n",
    "    WLE_MAT_200, \r\n",
    "    WLE_MAT_200_CORR, \r\n",
    "    pu_ma_no_corr, \r\n",
    "    n_stud_prev, \r\n",
    "    n_classi_prev, \r\n",
    "    LIVELLI, \r\n",
    "    Numeri, \r\n",
    "    Dati, \r\n",
    "    Riconoscere_forme, \r\n",
    "    Conoscere_padr, \r\n",
    "    Relazioni, \r\n",
    "    Spazio, \r\n",
    "    Acquisire, \r\n",
    "    Conoscere_util, \r\n",
    "    Rappresentare, \r\n",
    "    Riconoscere_contesti, \r\n",
    "    Risolvere, \r\n",
    "    Utilizzare     \r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {
    "id": "tWFBtGPFoCyW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Integer categorical features\r\n",
    "sesso_encoded = encode_categorical_feature(sesso, \"sesso\", train_ds, False)\r\n",
    "Pon_encoded = encode_categorical_feature(Pon, \"Pon\", train_ds, False)\r\n",
    "\r\n",
    "n_stud_prev_encoded = encode_numerical_feature(n_stud_prev, \"n_stud_prev\", train_ds)\r\n",
    "n_classi_prev_encoded = encode_numerical_feature(n_classi_prev, \"n_classi_prev\", train_ds)\r\n",
    "pu_ma_gr_encoded = encode_numerical_feature(pu_ma_gr, \"pu_ma_gr\", train_ds)\r\n",
    "pu_ma_no_encoded = encode_numerical_feature(pu_ma_no, \"pu_ma_no\", train_ds)\r\n",
    "Fattore_correzione_new_encoded = encode_numerical_feature(Fattore_correzione_new, \"Fattore_correzione_new\", train_ds)\r\n",
    "Cheating_encoded = encode_numerical_feature(Cheating, \"Cheating\", train_ds)\r\n",
    "WLE_MAT_encoded = encode_numerical_feature(WLE_MAT, \"WLE_MAT\", train_ds)\r\n",
    "WLE_MAT_200_encoded = encode_numerical_feature(WLE_MAT_200, \"WLE_MAT_200\", train_ds)\r\n",
    "WLE_MAT_200_CORR_encoded = encode_numerical_feature(WLE_MAT_200_CORR, \"WLE_MAT_200_CORR\", train_ds)\r\n",
    "pu_ma_no_corr_encoded = encode_numerical_feature(pu_ma_no_corr, \"pu_ma_no_corr\", train_ds)\r\n",
    "Numeri_encoded = encode_numerical_feature(Numeri, \"Numeri\", train_ds)\r\n",
    "Dati_encoded = encode_numerical_feature(Dati, \"Dati e previsioni\", train_ds)\r\n",
    "Riconoscere_forme_encoded = encode_numerical_feature(Riconoscere_forme, \"Riconoscere le forme nello spazio e utilizzarle per la risoluzione di problemi geometrici o di modellizzazione\", train_ds)\r\n",
    "Conoscere_padr_encoded = encode_numerical_feature(Conoscere_padr, \"Conoscere e padroneggiare i contenuti specifici della matematica\", train_ds)\r\n",
    "Relazioni_encoded = encode_numerical_feature(Relazioni, \"Relazioni e funzioni\", train_ds)\r\n",
    "Spazio_encoded = encode_numerical_feature(Spazio, \"Spazio figure\", train_ds)\r\n",
    "Acquisire_encoded = encode_numerical_feature(Acquisire, \"Acquisire progressivamente forme tipiche del pensiero matematico\", train_ds)\r\n",
    "Conoscere_util_encoded = encode_numerical_feature(Conoscere_util, \"Conoscere e utilizzare algoritmi e procedure\", train_ds)\r\n",
    "Rappresentare_encoded = encode_numerical_feature(Rappresentare, \"Rappresentare relazioni e dati e, in situazioni significative, utilizzare le rappresentazioni per ricavare informazioni, formulare giudizi e prendere decisioni\", train_ds)\r\n",
    "Riconoscere_contesti_encoded = encode_numerical_feature(Riconoscere_contesti, \"Riconoscere in contesti diversi il carattere misurabile di oggetti e fenomeni, utilizzare strumenti di misura, misurare grandezze, stimare misure di grandezze\", train_ds)\r\n",
    "Risolvere_encoded = encode_numerical_feature(Risolvere, \"Risolvere problemi utilizzando strategie in ambiti diversi ‚Äì numerico, geometrico, algebrico ‚Äì\", train_ds)\r\n",
    "Utilizzare_encoded = encode_numerical_feature(Utilizzare, \"Utilizzare strumenti, modelli e rappresentazioni nel trattamento quantitativo dell'informazione in ambito scientifico, tecnologico, economico e sociale\", train_ds)\r\n",
    "\r\n",
    "prog_encoded = encode_categorical_feature(prog, \"prog\", train_ds, False)\r\n",
    "mese_encoded = encode_categorical_feature(mese, \"mese\", train_ds, False)\r\n",
    "anno_encoded = encode_categorical_feature(anno, \"anno\", train_ds, False)\r\n",
    "luogo_encoded = encode_categorical_feature(luogo, \"luogo\", train_ds, False)\r\n",
    "eta_encoded = encode_categorical_feature(eta, \"eta\", train_ds, False)\r\n",
    "freq_asilo_nido_encoded = encode_categorical_feature(freq_asilo_nido, \"freq_asilo_nido\", train_ds, False)\r\n",
    "freq_scuola_materna_encoded = encode_categorical_feature(freq_scuola_materna, \"freq_scuola_materna\", train_ds, False)\r\n",
    "luogo_padre_encoded = encode_categorical_feature(luogo_padre, \"luogo_padre\", train_ds, False)\r\n",
    "titolo_padre_encoded = encode_categorical_feature(titolo_padre, \"titolo_padre\", train_ds, False)\r\n",
    "prof_padre_encoded = encode_categorical_feature(prof_padre, \"prof_padre\", train_ds, False)\r\n",
    "luogo_madre_encoded = encode_categorical_feature(luogo_madre, \"luogo_madre\", train_ds, False)\r\n",
    "titolo_madre_encoded = encode_categorical_feature(titolo_madre, \"titolo_madre\", train_ds, False)\r\n",
    "prof_madre_encoded = encode_categorical_feature(prof_madre, \"prof_madre\", train_ds, False)\r\n",
    "regolarit√†_encoded = encode_categorical_feature(regolarit√†, \"regolarit√†\", train_ds, False)\r\n",
    "cittadinanza_encoded = encode_categorical_feature(cittadinanza, \"cittadinanza\", train_ds, False)\r\n",
    "cod_provincia_ISTAT_encoded = encode_categorical_feature(cod_provincia_ISTAT, \"cod_provincia_ISTAT\", train_ds, False)\r\n",
    "sigla_provincia_istat_encoded = encode_categorical_feature(sigla_provincia_istat, \"sigla_provincia_istat\", train_ds, False)\r\n",
    "Nome_reg_encoded = encode_categorical_feature(Nome_reg, \"Nome_reg\", train_ds, False)\r\n",
    "Cod_reg_encoded = encode_categorical_feature(Cod_reg, \"Cod_reg\", train_ds, False)\r\n",
    "Areageo_3_encoded = encode_categorical_feature(Areageo_3, \"Areageo_3\", train_ds, False)\r\n",
    "Areageo_4_encoded = encode_categorical_feature(Areageo_4, \"Areageo_4\", train_ds, False)\r\n",
    "Areageo_5_encoded = encode_categorical_feature(Areageo_5, \"Areageo_5\", train_ds, False)\r\n",
    "Areageo_5_Istat_encoded = encode_categorical_feature(Areageo_5_Istat, \"Areageo_5_Istat\", train_ds, False)\r\n",
    "LIVELLI_encoded = encode_categorical_feature(LIVELLI, \"LIVELLI\", train_ds, False)\r\n",
    "\r\n",
    "\r\n",
    "# Numerical features"
   ],
   "outputs": [],
   "metadata": {
    "id": "srzHs3M0rGy9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for key, value in train_dataset.dtypes.items() :\r\n",
    "    \r\n",
    "        print(key) "
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_zC5oxYoIOZ",
    "outputId": "059741d0-7a25-41ae-a0e9-0c82ef112d4c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_features = layers.concatenate(\r\n",
    "    [\r\n",
    "        prog_encoded, \r\n",
    "        sesso_encoded, \r\n",
    "        mese_encoded, \r\n",
    "        anno_encoded, \r\n",
    "        luogo_encoded, \r\n",
    "        eta_encoded, \r\n",
    "        freq_asilo_nido_encoded, \r\n",
    "        freq_scuola_materna_encoded, \r\n",
    "        luogo_padre_encoded, \r\n",
    "        titolo_padre_encoded, \r\n",
    "        prof_padre_encoded, \r\n",
    "        luogo_madre_encoded, \r\n",
    "        titolo_madre_encoded, \r\n",
    "        prof_madre_encoded, \r\n",
    "        regolarit√†_encoded, \r\n",
    "        cittadinanza_encoded, \r\n",
    "        cod_provincia_ISTAT_encoded, \r\n",
    "        sigla_provincia_istat_encoded, \r\n",
    "        Nome_reg_encoded, \r\n",
    "        Cod_reg_encoded, \r\n",
    "        Areageo_3_encoded, \r\n",
    "        Areageo_4_encoded, \r\n",
    "        Areageo_5_encoded, \r\n",
    "        Areageo_5_Istat_encoded, \r\n",
    "        Pon_encoded, \r\n",
    "        pu_ma_gr_encoded, \r\n",
    "        pu_ma_no_encoded, \r\n",
    "        Fattore_correzione_new_encoded, \r\n",
    "        Cheating_encoded, \r\n",
    "        WLE_MAT_encoded, \r\n",
    "        WLE_MAT_200_encoded, \r\n",
    "        WLE_MAT_200_CORR_encoded, \r\n",
    "        pu_ma_no_corr_encoded, \r\n",
    "        n_stud_prev_encoded, \r\n",
    "        n_classi_prev_encoded, \r\n",
    "        LIVELLI_encoded, \r\n",
    "        Numeri_encoded, \r\n",
    "        Dati_encoded, \r\n",
    "        Riconoscere_forme_encoded, \r\n",
    "        Conoscere_padr_encoded, \r\n",
    "        Relazioni_encoded, \r\n",
    "        Spazio_encoded, \r\n",
    "        Acquisire_encoded, \r\n",
    "        Conoscere_util_encoded, \r\n",
    "        Rappresentare_encoded, \r\n",
    "        Riconoscere_contesti_encoded, \r\n",
    "        Risolvere_encoded, \r\n",
    "        Utilizzare_encoded\r\n",
    "    ]\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "id": "3lrPyVrGuEDP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras import metrics\r\n",
    "from tensorflow.keras import optimizers\r\n",
    "from tensorflow.keras import losses\r\n",
    "\r\n",
    "x = layers.Dense(32, activation=\"relu\")(all_features)\r\n",
    "x = layers.Dropout(0.5)(x)\r\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\r\n",
    "model = keras.Model(all_inputs, output)\r\n",
    "\r\n",
    "model.compile(optimizer=optimizers.Adam(),\r\n",
    "              loss=losses.BinaryCrossentropy(),\r\n",
    "              metrics=[metrics.Accuracy(),\r\n",
    "                       metrics.Precision(),\r\n",
    "                       metrics.Recall(),\r\n",
    "                       metrics.FalseNegatives(),\r\n",
    "                       metrics.FalsePositives(),\r\n",
    "                       metrics.TrueNegatives(),\r\n",
    "                       metrics.TruePositives()])"
   ],
   "outputs": [],
   "metadata": {
    "id": "85iF60GkvWuO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "z_DuwTPqvbcw",
    "outputId": "076d8632-555f-4123-d2cc-573a612c37eb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# addestramento del modello\r\n",
    "model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "dOP1zTVkve81",
    "outputId": "bda2d827-cb33-4aca-855c-7512523b0228"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sample = {\r\n",
    "    \"age\": 60,\r\n",
    "    \"sex\": 1,\r\n",
    "    \"cp\": 1,\r\n",
    "    \"trestbps\": 145,\r\n",
    "    \"chol\": 233,\r\n",
    "    \"fbs\": 1,\r\n",
    "    \"restecg\": 2,\r\n",
    "    \"thalach\": 150,\r\n",
    "    \"exang\": 0,\r\n",
    "    \"oldpeak\": 2.3,\r\n",
    "    \"slope\": 3,\r\n",
    "    \"ca\": 0,\r\n",
    "    \"thal\": \"fixed\",\r\n",
    "}\r\n",
    "\r\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\r\n",
    "predictions = model.predict(input_dict)\r\n",
    "\r\n",
    "print(\r\n",
    "    \"This particular patient had a %.1f percent probability \"\r\n",
    "    \"of having a heart disease, as evaluated by our model.\" % (100 * predictions[0][0],)\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "id": "-3RkehPGwJdn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ESEGUI QUEST'ULTIMA CELLA PER SMONTARE GDRIVE"
   ],
   "metadata": {
    "id": "mVXPbWHEil7M"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "drive.flush_and_unmount()\r\n",
    "print('All changes made in this colab session should now be visible in Drive.')"
   ],
   "outputs": [],
   "metadata": {
    "id": "tpuu1v81gsYr"
   }
  }
 ]
}